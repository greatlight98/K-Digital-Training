{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6-3_model_imdb_glove.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOy1P9YE87rAnMUJGk7bwbH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zza1k_KOvt1P","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1593193760068,"user_tz":-540,"elapsed":3842,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"b6067a2d-a2df-48ad-99fc-c303c314c453"},"source":["! pip list | grep \"torch\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch                    1.5.1+cu101    \n","torchsummary             1.5.1          \n","torchtext                0.3.1          \n","torchvision              0.6.1+cu101    \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aJGwgEKR_GPg","colab_type":"code","colab":{}},"source":["import re\n","import sys\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torchtext import data\n","from torchtext import datasets"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3O6ttcHKrIq","colab_type":"text"},"source":["## Reading Data"]},{"cell_type":"code","metadata":{"id":"1oJjy5xBJXAx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592902913534,"user_tz":-540,"elapsed":40011,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"908db91e-d7e6-4d9e-aa4c-947fb94b0ceb"},"source":["# Data Setting\n","TEXT = data.Field(batch_first = True,\n","                  fix_length = 500,\n","                  tokenize=str.split,\n","                  pad_first=True,\n","                  pad_token='[PAD]',\n","                  unk_token='[UNK]')\n","\n","LABEL = data.LabelField(dtype=torch.float)\n","\n","train_data, test_data = datasets.IMDB.splits(text_field = TEXT, \n","                                             label_field = LABEL)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["aclImdb_v1.tar.gz:   0%|          | 147k/84.1M [00:00<01:02, 1.34MB/s]"],"name":"stderr"},{"output_type":"stream","text":["downloading aclImdb_v1.tar.gz\n"],"name":"stdout"},{"output_type":"stream","text":["aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 60.6MB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"34DoliQ6mdob","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592902913535,"user_tz":-540,"elapsed":39995,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"ff456955-ee36-4017-d81c-9eccc8d4347a"},"source":["# Data Length\n","print(f'Train Data Length : {len(train_data.examples)}')\n","print(f'Test Data Length : {len(test_data.examples)}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Data Length : 25000\n","Test Data Length : 25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3UNJJZE0mH75","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592902913536,"user_tz":-540,"elapsed":39980,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"720cf3db-9fc6-4ea0-90af-d1003255b9f1"},"source":["# Data Fields\n","train_data.fields"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'label': <torchtext.data.field.LabelField at 0x7f2cb75a9240>,\n"," 'text': <torchtext.data.field.Field at 0x7f2cb75a9fd0>}"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"ViUZ13AM_HFQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"executionInfo":{"status":"ok","timestamp":1592902913537,"user_tz":-540,"elapsed":38923,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"cd86dc6c-3ffc-4d03-c8b6-f9826986d6fc"},"source":["# Data Sample\n","print('---- Data Sample ----')\n","print('Input : ')\n","print(' '.join(vars(train_data.examples[1])['text']),'\\n')\n","print('Label : ')\n","print(vars(train_data.examples[1])['label'])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---- Data Sample ----\n","Input : \n","This is definitely an appropriate update for the original, except that \"party on the left is now party on the right.\" Like the original, this movie rails against a federal government which oversteps its bounds with regards to personal liberty. It is a warning of how tenuous our political liberties are in an era of an over-zealous, and over-powerful federal government. Kowalski serves as a metaphor for Waco and Ruby Ridge, where the US government, with the cooperation of the mainstream media, threw around words like \"white supremacist\" and \"right wing extremists as well as trumped-up drug charges to abridge the most fundamental of its' citizens rights, with the willing acquiescence of the general populace. That message is so non-PC, I am stunned that this film could be made - at least not without bringing the Federal government via the IRS down on the makers like they did to Juanita Broderick, Katherine Prudhomme, the Western Journalism Center, and countless others who dared to speak out. \"Live Free or Die\" is the motto on Jason Priestly's hat as he brilliantly portrays \"the voice,\" and that sums up the dangerous (to some) message of this film.<br /><br /> \n","\n","Label : \n","pos\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pn4ddGIQLL_u","colab_type":"text"},"source":["## Pre-processing Data"]},{"cell_type":"code","metadata":{"id":"gpIQqgb_G41G","colab_type":"code","colab":{}},"source":["def PreProcessingText(input_sentence):\n","    input_sentence = input_sentence.lower() # 소문자화\n","    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n","    input_sentence = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n","    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n","    if input_sentence:\n","        return input_sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5cIqIf34a2SR","colab_type":"code","colab":{}},"source":["for example in train_data.examples:\n","    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n","    \n","for example in test_data.examples:\n","    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iSucMR06LR8Y","colab_type":"text"},"source":["## Making Vocab & Setting Embedding"]},{"cell_type":"code","metadata":{"id":"NBI0uTQUSbdt","colab_type":"code","colab":{}},"source":["model_config = {'emb_type' : 'glove', 'emb_dim' : 300}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LGSnQIsAHcv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592903454602,"user_tz":-540,"elapsed":474879,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"fc9cad0e-5496-4d0d-8805-277e496c60d9"},"source":["# making vocab\n","TEXT.build_vocab(train_data,\n","                 min_freq = 2, \n","                 max_size = None,\n","                 vectors = f\"glove.6B.{model_config['emb_dim']}d\")\n","\n","## vector list\n","# charngram.100d\n","# fasttext.en.300d\n","# fasttext.simple.300d\n","# glove.42B.300d\n","# glove.840B.300d\n","# glove.twitter.27B.25d\n","# glove.twitter.27B.50d\n","# glove.twitter.27B.100d\n","# glove.twitter.27B.200d\n","# glove.6B.50d\n","# glove.6B.100d\n","# glove.6B.200d\n","# glove.6B.300d\n","\n","LABEL.build_vocab(train_data)\n","\n","model_config['vocab_size'] = len(TEXT.vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":[".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n","100%|█████████▉| 399257/400000 [00:54<00:00, 7779.24it/s]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vt7ulofTn6U4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1592903455613,"user_tz":-540,"elapsed":998,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"b8092f84-74ee-44f1-c58f-c4f6dd36a980"},"source":["# Vocabulary Info\n","print(f'Vocab Size : {len(TEXT.vocab)}')\n","\n","print('Vocab Examples : ')\n","for idx, (k, v) in enumerate(TEXT.vocab.stoi.items()):\n","    if idx >= 10:\n","        break    \n","    print('\\t', k, v)\n","\n","print('---------------------------------')\n","\n","# Label Info\n","print(f'Label Size : {len(LABEL.vocab)}')\n","\n","print('Lable Examples : ')\n","for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n","    print('\\t', k, v)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Vocab Size : 51956\n","Vocab Examples : \n","\t [UNK] 0\n","\t [PAD] 1\n","\t the 2\n","\t and 3\n","\t a 4\n","\t of 5\n","\t to 6\n","\t is 7\n","\t in 8\n","\t it 9\n","---------------------------------\n","Label Size : 2\n","Lable Examples : \n","\t neg 0\n","\t pos 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s7dLNrxJMmEF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592903455887,"user_tz":-540,"elapsed":1262,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"e102b9b7-beb6-4c2a-f27a-c0f75cb17bc0"},"source":["# Check embedding vectors\n","TEXT.vocab.vectors.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([51956, 300])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"zuSh9SlQLfGp","colab_type":"text"},"source":["## Spliting Validation Data & Making Data Iterator"]},{"cell_type":"code","metadata":{"id":"CbH-Rha8___V","colab_type":"code","colab":{}},"source":["# Spliting Valid set\n","train_data, valid_data = train_data.split(random_state = random.seed(0),\n","                                          split_ratio=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LKOfVNAwAJLU","colab_type":"code","colab":{}},"source":["model_config['batch_size'] = 30\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size=model_config['batch_size'],\n","    device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8OFTE-xAwJYb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1592903464561,"user_tz":-540,"elapsed":9903,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"14d28cc2-d8ad-45e4-9dbc-f87411af7d79"},"source":["# Check batch data\n","sample_for_check = next(iter(train_iterator))\n","print(sample_for_check)\n","print(sample_for_check.text)\n","print(sample_for_check.label)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","[torchtext.data.batch.Batch of size 30]\n","\t[.text]:[torch.cuda.LongTensor of size 30x500 (GPU 0)]\n","\t[.label]:[torch.cuda.FloatTensor of size 30 (GPU 0)]\n","tensor([[   1,    1,    1,  ...,   43,    5,  155],\n","        [   1,    1,    1,  ...,   25,    6,  132],\n","        [   1,    1,    1,  ...,   40, 1041,   75],\n","        ...,\n","        [   1,    1,    1,  ...,    5,   65, 1258],\n","        [ 100,  462,   58,  ...,    3,  148,   56],\n","        [   1,    1,    1,  ...,  979,  719,  123]], device='cuda:0')\n","tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n","        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NU1fESnXyR9E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1592903464562,"user_tz":-540,"elapsed":9891,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"49a58843-8f07-4c0c-f7b8-47a6ad1813b8"},"source":["# Check reverting data\n","print(' '.join([TEXT.vocab.itos[int(x)] for x in sample_for_check.text[0,:] if x not in [0,1]]))\n","print(LABEL.vocab.itos[int(sample_for_check.label[0])]) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["i'm a fan of both shakespeare and mst3k so i waited anxiously to see this episode i'll comment on the movie first then the mst3k episode the recipe for this movie take talented actors rich and beautiful shakespeare material and a 1 25 budget mix well then drain of all life and movement until dull and lifeless serve cold in a big plain stone cauldron movie i give 3 out of 10 because the actors at least deserve a little bit of credit okay now the mst3k episode i'll admit it the first time i saw it i fell asleep halfway through i understand that was the reaction of several other as well however when i watched it a second time i realized that there was a whole host of intelligent references and good lines i missed the first time around the trick with this episode is listen carefully it takes a couple of viewings to catch each line give it a second chance and you'll see what i mean mst3k episode 7 1 2 out of 10\n","neg\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cZXWakE7MxU8","colab_type":"text"},"source":["## Making Model"]},{"cell_type":"code","metadata":{"id":"CD2AK0NMAKr1","colab_type":"code","colab":{}},"source":["class SentenceClassification(nn.Module):\n","    def __init__(self, **model_config):\n","        super(SentenceClassification, self).__init__()\n","\n","        if model_config['emb_type'] == 'glove' or 'fasttext':\n","            self.emb = nn.Embedding(model_config['vocab_size'],\n","                                    model_config['emb_dim'],\n","                                    _weight = TEXT.vocab.vectors)\n","        else:\n","            self.emb = nn.Embedding(model_config['vocab_size'],\n","                                    model_config['emb_dim'])\n","        \n","        self.bidirectional = model_config['bidirectional']\n","        self.num_direction = 2 if model_config['bidirectional'] else 1\n","        self.model_type = model_config['model_type'] \n","\n","        self.RNN = nn.RNN (input_size = model_config['emb_dim'],\n","                           hidden_size = model_config['hidden_dim'],\n","                           dropout=model_config['dropout'],\n","                           bidirectional = model_config['bidirectional'],\n","                           batch_first = model_config['batch_first'])\n","        \n","        self.LSTM= nn.LSTM(input_size = model_config['emb_dim'],\n","                           hidden_size = model_config['hidden_dim'],\n","                           dropout=model_config['dropout'],\n","                           bidirectional = model_config['bidirectional'],\n","                           batch_first = model_config['batch_first'])\n","        \n","        self.GRU = nn.GRU (input_size = model_config['emb_dim'],\n","                           hidden_size = model_config['hidden_dim'],\n","                           dropout=model_config['dropout'],\n","                           bidirectional = model_config['bidirectional'],\n","                           batch_first = model_config['batch_first'])\n","    \n","        self.fc = nn.Linear(model_config['hidden_dim'] * self.num_direction,\n","                            model_config['output_dim'])\n","        \n","        self.drop = nn.Dropout(model_config['dropout'])\n","\n","    def forward(self, x):\n","        \n","        emb = self.emb(x) \n","        # emb : (Batch_Size, Max_Seq_Length, Emb_dim)\n","\n","        if self.model_type == 'RNN':\n","            output, hidden = self.RNN(emb) \n","        elif self.model_type == 'LSTM':\n","            output, (hidden, cell) = self.LSTM(emb)\n","        elif self.model_type == 'GRU':\n","            output, hidden = self.GRU(emb)\n","        else:\n","            raise NameError('Select model_type in [RNN, LSTM, GRU]')\n","        \n","        # output : (Batch_Size, Max_Seq_Length, Hidden_dim * num_direction) \n","        # hidden : (num_direction, Batch_Size, Hidden_dim)\n","        \n","        last_output = output[:,-1,:]\n","\n","        # last_output : (Batch_Size, Hidden_dim * num_direction)\n","        return self.fc(self.drop(last_output))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X_3DNQR3M30p","colab_type":"text"},"source":["### Checking feed-forward"]},{"cell_type":"code","metadata":{"id":"8676uoMayZWm","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r3VJ5BuHkm-4","colab_type":"code","colab":{}},"source":["model_config.update(dict(batch_first = True,\n","                         model_type = 'RNN',\n","                         bidirectional = True,\n","                         hidden_dim = 128,\n","                         output_dim = 1,\n","                         dropout = 0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWYjr7KQZxXu","colab_type":"code","colab":{}},"source":["model = SentenceClassification(**model_config).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhGNULElZuI_","colab_type":"code","colab":{}},"source":["predictions = model.forward(sample_for_check.text).squeeze()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wabzuaD1AKjF","colab_type":"code","colab":{}},"source":["loss_fn = nn.BCEWithLogitsLoss().to(device)\n","\n","def binary_accuracy(preds, y):\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() \n","    acc = correct.sum()/len(correct)\n","    return acc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HdOXGw9ze-lI","colab_type":"code","colab":{}},"source":["loss = loss_fn(predictions, sample_for_check.label)\n","acc = binary_accuracy(predictions, sample_for_check.label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s5OBri4AsPVy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1592903464814,"user_tz":-540,"elapsed":10106,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"85ab47d2-903a-489b-d845-f74ef20a7e1d"},"source":["print(predictions)\n","print(loss, acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([ 0.0277,  0.1755,  0.1101,  0.1844,  0.1224,  0.0432,  0.0808,  0.1359,\n","         0.1876,  0.2485, -0.1904,  0.2088,  0.0112, -0.1296,  0.1382, -0.0276,\n","        -0.0993,  0.0076,  0.2053,  0.2591,  0.0259, -0.0386,  0.0600,  0.0376,\n","         0.2082,  0.1412, -0.0776,  0.2972, -0.0063,  0.0902], device='cuda:0',\n","       grad_fn=<SqueezeBackward0>)\n","tensor(0.6876, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) tensor(0.4667, device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rswNBOAzoImC","colab_type":"text"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"WCgs1fdcAKXF","colab_type":"code","colab":{}},"source":["def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    model.train() \n","    batch_size = model_params['batch_size']\n","\n","    for idx, batch in enumerate(iterator):\n","        \n","        # Initializing\n","        optimizer.zero_grad()\n","        \n","        # Forward \n","        predictions = model(batch.text).squeeze()\n","        loss = loss_fn(predictions, batch.label)\n","        acc = binary_accuracy(predictions, batch.label)\n","        \n","        sys.stdout.write(\n","                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n","                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n","                    f\"  Loss: {loss.item():.4}\"\\\n","                    f\"  Acc : {acc.item():.4}\"\\\n","                    )\n","\n","        # Backward \n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Update Epoch Performance\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","        \n","    return epoch_loss/len(iterator) , epoch_acc/len(iterator) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3zqJ1gkFARwp","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, loss_fn):\n","    \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    \n","    # evaluation mode\n","    model.eval()\n","    with torch.no_grad():\n","        for batch in iterator:\n","            predictions = model(batch.text).squeeze(1)\n","            loss = loss_fn(predictions, batch.label)\n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIA_7QQzoLK1","colab_type":"text"},"source":["### bi-RNN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n6GtVuVFUHqz","colab":{}},"source":["model_config['model_type'] = 'RNN'\n","model = SentenceClassification(**model_config).to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","loss_fn = nn.BCEWithLogitsLoss().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uTvlbDLnUHq2","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1592903783645,"user_tz":-540,"elapsed":318790,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"fe52341b-63f0-49ab-b088-097cf18060a1"},"source":["N_EPOCH = 5\n","\n","best_valid_loss = float('inf')\n","model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n","\n","print('---------------------------------')\n","print(f'Model name : {model_name}')\n","print('---------------------------------')\n","\n","for epoch in range(N_EPOCH):\n","    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n","    print('')\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), f'./{model_name}.pt')\n","        print(f'\\t Saved at {epoch}-epoch')\n","\n","    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n","    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---------------------------------\n","Model name : bi-RNN_glove\n","---------------------------------\n","[Train] Epoch :  0 [300 / 20010 (1.499%)]  Loss: 0.7234  Acc : 0.4"],"name":"stdout"},{"output_type":"stream","text":["\r100%|█████████▉| 399257/400000 [01:10<00:00, 7779.24it/s]"],"name":"stderr"},{"output_type":"stream","text":["[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.7114  Acc : 0.5333\n","\t Saved at 0-epoch\n","\t Epoch : 0 | Train Loss : 0.6581 | Train Acc : 0.6003\n","\t Epoch : 0 | Valid Loss : 0.6463 | Valid Acc : 0.602\n","[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.5973  Acc : 0.7333\n","\t Saved at 1-epoch\n","\t Epoch : 1 | Train Loss : 0.5982 | Train Acc : 0.672\n","\t Epoch : 1 | Valid Loss : 0.6225 | Valid Acc : 0.6377\n","[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.5563  Acc : 0.6667\n","\t Epoch : 2 | Train Loss : 0.5166 | Train Acc : 0.7397\n","\t Epoch : 2 | Valid Loss : 0.6226 | Valid Acc : 0.6489\n","[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.3558  Acc : 0.7667\n","\t Epoch : 3 | Train Loss : 0.4328 | Train Acc : 0.7874\n","\t Epoch : 3 | Valid Loss : 0.6395 | Valid Acc : 0.6697\n","[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.474  Acc : 0.8333\n","\t Epoch : 4 | Train Loss : 0.3694 | Train Acc : 0.8235\n","\t Epoch : 4 | Valid Loss : 0.6731 | Valid Acc : 0.6962\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"akDRWiykUHq5","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592904013732,"user_tz":-540,"elapsed":30044,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"f1089f30-ec57-49ba-c78f-0f73f4f2d3a3"},"source":["# Test set\n","model.load_state_dict(torch.load(f'./{model_name}.pt'))\n","test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n","print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Loss : 0.6279 | Test Acc : 0.6376\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uxG4rgwTo8D7"},"source":["### bi-LSTM"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wpW7ui5mUBTk","colab":{}},"source":["model_config['model_type'] = 'LSTM'\n","model = SentenceClassification(**model_config).to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","loss_fn = nn.BCEWithLogitsLoss().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CDN-nLxJUBTo","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1592904863046,"user_tz":-540,"elapsed":403700,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"e6996ed9-0f51-4cdb-8d82-707602a82575"},"source":["N_EPOCH = 5\n","\n","best_valid_loss = float('inf')\n","model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n","\n","print('---------------------------------')\n","print(f'Model name : {model_name}')\n","print('---------------------------------')\n","\n","for epoch in range(N_EPOCH):\n","    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n","    print('')\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), f'./{model_name}.pt')\n","        print(f'\\t Saved at {epoch}-epoch')\n","\n","    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n","    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---------------------------------\n","Model name : bi-LSTM_glove\n","---------------------------------\n","[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.3941  Acc : 0.8333\n","\t Saved at 0-epoch\n","\t Epoch : 0 | Train Loss : 0.5186 | Train Acc : 0.7519\n","\t Epoch : 0 | Valid Loss : 0.4804 | Valid Acc : 0.7905\n","[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.3686  Acc : 0.8667\n","\t Saved at 1-epoch\n","\t Epoch : 1 | Train Loss : 0.2476 | Train Acc : 0.9031\n","\t Epoch : 1 | Valid Loss : 0.2687 | Valid Acc : 0.8921\n","[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.012  Acc : 1.0\n","\t Epoch : 2 | Train Loss : 0.08126 | Train Acc : 0.9743\n","\t Epoch : 2 | Valid Loss : 0.3457 | Valid Acc : 0.8765\n","[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.006134  Acc : 1.0\n","\t Epoch : 3 | Train Loss : 0.02272 | Train Acc : 0.9942\n","\t Epoch : 3 | Valid Loss : 0.5078 | Valid Acc : 0.8791\n","[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.002149  Acc : 1.0\n","\t Epoch : 4 | Train Loss : 0.008174 | Train Acc : 0.9981\n","\t Epoch : 4 | Valid Loss : 0.5812 | Valid Acc : 0.8673\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"d8qjmPU7UBTq","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592904894172,"user_tz":-540,"elapsed":430792,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"3ad69658-a57d-4e05-87a9-cb5a7ea8f653"},"source":["# Test set\n","model.load_state_dict(torch.load(f'./{model_name}.pt'))\n","test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n","print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Loss : 0.2932 | Test Acc : 0.8818\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FfDGBCWRxnB_"},"source":["### bi-GRU"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"khyItx4zxnCA","colab":{}},"source":["model_config['model_type'] = 'GRU'\n","model = SentenceClassification(**model_config).to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","loss_fn = nn.BCEWithLogitsLoss().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"om_7UjicxnCD","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1592905283205,"user_tz":-540,"elapsed":813897,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"604af6c1-e459-42ac-892a-02077047d007"},"source":["N_EPOCH = 5\n","\n","best_valid_loss = float('inf')\n","model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n","\n","print('---------------------------------')\n","print(f'Model name : {model_name}')\n","print('---------------------------------')\n","\n","for epoch in range(N_EPOCH):\n","    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n","    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n","    print('')\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), f'./{model_name}.pt')\n","        print(f'\\t Saved at {epoch}-epoch')\n","\n","    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n","    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---------------------------------\n","Model name : bi-GRU_glove\n","---------------------------------\n","[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.4295  Acc : 0.7333\n","\t Saved at 0-epoch\n","\t Epoch : 0 | Train Loss : 0.4084 | Train Acc : 0.8079\n","\t Epoch : 0 | Valid Loss : 0.2917 | Valid Acc : 0.8721\n","[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.1963  Acc : 0.9\n","\t Saved at 1-epoch\n","\t Epoch : 1 | Train Loss : 0.1432 | Train Acc : 0.9469\n","\t Epoch : 1 | Valid Loss : 0.277 | Valid Acc : 0.8863\n","[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.007014  Acc : 1.0\n","\t Epoch : 2 | Train Loss : 0.03757 | Train Acc : 0.9888\n","\t Epoch : 2 | Valid Loss : 0.4066 | Valid Acc : 0.8774\n","[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.004141  Acc : 1.0\n","\t Epoch : 3 | Train Loss : 0.00821 | Train Acc : 0.998\n","\t Epoch : 3 | Valid Loss : 0.5396 | Valid Acc : 0.8798\n","[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.009704  Acc : 1.0\n","\t Epoch : 4 | Train Loss : 0.008131 | Train Acc : 0.9979\n","\t Epoch : 4 | Valid Loss : 0.4654 | Valid Acc : 0.8675\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZOL9MoBWxnCG","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592905313976,"user_tz":-540,"elapsed":842708,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"de53c613-9f09-476a-aa63-cd4f2120aa5b"},"source":["# Test set\n","model.load_state_dict(torch.load(f'./{model_name}.pt'))\n","test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n","print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Loss : 0.2969 | Test Acc : 0.8774\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GEWK8wnkuEzA","colab_type":"text"},"source":["## Inference"]},{"cell_type":"code","metadata":{"id":"x5VKyllQuReq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592905313977,"user_tz":-540,"elapsed":840929,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"0188fc29-abeb-430e-8d45-71aa2e6ecef4"},"source":["model_config['model_type'] = 'GRU'\n","model = SentenceClassification(**model_config).to(device)\n","model.load_state_dict(torch.load(f\"./{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}.pt\"))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"MPifO6k5ugGG","colab_type":"code","colab":{}},"source":["def predict_sentiment(model, sentence):\n","    model.eval()\n","    indexed = TEXT.numericalize(TEXT.pad([TEXT.tokenize(PreProcessingText(sentence))]))\n","    input_data = torch.LongTensor(indexed).to(device)\n","    prediction = torch.sigmoid(model(input_data))\n","    return prediction.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gY4lDbr-xB7V","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592905313978,"user_tz":-540,"elapsed":839339,"user":{"displayName":"seongsu bang","photoUrl":"","userId":"06124410414614761416"}},"outputId":"27f24a58-c4fa-449b-aad5-ac854af7206e"},"source":["test_sentence = 'this movie is FUN'\n","predict_sentiment(model = model, sentence = test_sentence)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8924493193626404"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"azk3LxqLxdTy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}