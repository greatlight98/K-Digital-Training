{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Convolution 이란?\n",
    " - 이미지는 컴퓨터가 받아드리기에 Gray-scale 혹은 RGB의 숫자이다. 또한 필터는 사용자가 찾고자 하는 피쳐의 숫자 값들이다.\n",
    " - Convolution은 필터 값이 input 이미지와 얼마나 겹치는가를 연산하여 출력한다. 값이 클 수록 사용자가 찾고자 하는 피쳐(필터)와 닮은 부분이다!\n",
    " - Convolution은 이미지 위에서 Stride 값 만큼 fiter(Kernel)을 이동시키면서 이미지와 필터가 겹쳐지는 부분의 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 연산이다.\n",
    " - Input 이미지에서 Stride 만큼 필터를 움직이며 연산되므로, output의 크기는 Input보다 줄어든다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Stride and Padding\n",
    "### (1) Stride\n",
    " - filter를 한 번에 얼마나 이동 할 것인가를 정의한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) Padding\n",
    " - Zero-padding\n",
    " - 패딩을 씌우고 싶은 곳 상하좌우로 0을 둘러싼다. (패딩을 씌운다.)\n",
    " - Padding에 1 값을 주면, 패딩을 1칸 씌운다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pytorch에서 Conv2d 이용하기\n",
    "### (1) Pytorchd의 Conv2d 도큐먼트 살펴보기\n",
    " - torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True)\n",
    " - 파리미터에 순서대로 인풋 채널, 아웃풋 채널, 커널(필터) 크기, Stride, Padding 등을 선언해 주면 된다.\n",
    " - 커널(필터) 크기를 정사각형으로 설정하려면 3 과 같이 설정하면 되고, 직사각형으로 설정하려면 (2, 4)와 같이 설정하면 된다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) Conv2d 예제\n",
    " - Convolution을 하나 만들어 보자! (인풋 채널 1, 3 * 3 크기의 채널 1 짜리 커널)\n",
    " - 여기서 인풋 채널 1의 뜻은 인풋 이미지가 Gray-scale이라는 것이고(3일 경우 RGB), 채널 1 짜리 커널의 뜻은 커널(필터)의 갯수가 1개 라는 것이다.\n",
    "\n",
    "```python\n",
    "# Convolution을 하나 만들어 보자!\n",
    "conv = nn.Conv2d(1, 1, 3) # 인풋 채널 1, 커널이 한 장이므로 아웃풋 채널도 1, 커널 크기는 3\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### (3) Conv2d 입력 형태\n",
    " - 앞에서 Conv2d로 Convolution을 만들어 놨다. 생성해 놓은 Convolution에는 어떤 값을 넣어서 이용할 수 있을까?\n",
    " - Conv2d에는 Tensor 타입을 입력해야 한다.\n",
    " - Conv2d에 들어가는 입력 값은 (batch_size, input channel, input height, input width)이다.\n",
    "\n",
    "```python\n",
    "conv = nn.Conv2d(1, 1, 3) # convolution을 만들어 놨다.\n",
    "output = conv(batch_size, input channel, input height, input width) # conv에 값들을 넣어서 이용하여, input 이미지에 convolution을 돌린 output을 구하자!\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "### (4) 요약 정리!\n",
    " - Input 이미지에 Convolution을 돌려서 Output을 얻으려면?\n",
    "#### 1. Convolution 만들기\n",
    " - 인풋 채널, 아웃풋 채널, 필터 크기, Stride, Padding 등을 설정해서 Convolution을 만들어 놓자.\n",
    " - 필터, Stride, Padding 등을 설정해 Convolution의 전체적인 아웃라인을 만들어 놓는다고 생각하면 된다!\n",
    " \n",
    "#### 2. Convolution 이용하기\n",
    " - 만들어 둔 conv에 batch_size, input channel, input height, input width 값을 넣어 Convolution을 이용하자.\n",
    " - 만들어 둔 conv에 input 이미지의 높이, 너비 등을 입력하여 실질적으로 Convolution을 이용한다고 생각하면 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Convolution의 Output 크기 예상하기\n",
    " - Input 이미지에 Convolution을 돌린 Output 이미지의 크기를 예상해 보자.\n",
    " - Output size = (input size - filter size + (2 * padding))/Stride + 1\n",
    "\n",
    "<br>\n",
    "\n",
    "### ex 1) Input Image가 정사각형인 경우!\n",
    " - input image size = 227 * 227\n",
    " - filter size = 11 * 11\n",
    " - stride = 4\n",
    " - pradding = 0\n",
    " - output image size = ((227 - 11 + 0)/4) + 1 = 55 => 55 * 55\n",
    "\n",
    "<br>\n",
    "\n",
    "### ex 2)\n",
    " - input image size = 64 * 64\n",
    " - filter size = 7 * 7\n",
    " - stride = 2\n",
    " - pradding = 0\n",
    " - output image size = ((64 - 7 + 0)/2) + 1 = 29.3 = 29 (소수점은 과감히 버린다!) => 29 * 29\n",
    "\n",
    "<br>\n",
    "\n",
    "### ex 3)\n",
    " - input image size = 32 * 32\n",
    " - filter size = 5 * 5\n",
    " - stride = 1\n",
    " - pradding = 2\n",
    " - output image size = ((32 - 5 + (2 * 2))/1) + 1 = 32 => 32 * 32\n",
    "\n",
    "<br>\n",
    "\n",
    "### ex 4) Input Image가 직사각형인 경우!\n",
    " - input image size = 32 * 64\n",
    " - filter size = 5 * 5\n",
    " - stride = 1\n",
    " - pradding = 0\n",
    " - output image size = (((32, 64) - 5 + 0)/1) + 1 = (27, 59) + 1 = (28, 60) => 28 * 60\n",
    " \n",
    "<br>\n",
    "\n",
    "### ex 5)\n",
    " - input image size = 64 * 32\n",
    " - filter size = 3 * 3\n",
    " - stride = 1\n",
    " - pradding = 1\n",
    " - output image size = (((64, 32) - 3 + 2)/1) + 1 = (63, 31) + 1 = (64, 32) => 64 * 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolution의 Output 크기 예상한 것 직접 코드로 확인 해보기\n",
    "### ex 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 55, 55])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convolution 만들기\n",
    "conv = nn.Conv2d(1, 1, 11, stride = 4, padding = 0) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정\n",
    "\n",
    "# conv에 넣기 위해 input을 tensor로 만들기\n",
    "inputs = torch.Tensor(1, 1, 227, 227) # batch size : 1, input channel : 1, input size : 227 * 227\n",
    "\n",
    "# Convolution 이용하기\n",
    "output = conv(inputs)\n",
    "\n",
    "output.shape # 55 * 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 29, 29])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convolution 만들기\n",
    "conv = nn.Conv2d(1, 1, 7, stride = 2, padding = 0) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정\n",
    "\n",
    "# conv에 넣기 위해 input을 tensor로 만들기\n",
    "inputs = torch.Tensor(1, 1, 64, 64) # batch size : 1, input channel : 1, input size : 64 * 64\n",
    "\n",
    "# Convolution 이용하기\n",
    "output = conv(inputs)\n",
    "\n",
    "output.shape # 29 * 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convolution 만들기\n",
    "conv = nn.Conv2d(1, 1, 5, stride = 1, padding = 2) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정\n",
    "\n",
    "# conv에 넣기 위해 input을 tensor로 만들기\n",
    "inputs = torch.Tensor(1, 1, 32, 32) # batch size : 1, input channel : 1, input size : 32 * 32\n",
    "\n",
    "# Convolution 이용하기\n",
    "output = conv(inputs)\n",
    "\n",
    "output.shape # 32 * 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 60])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convolution 만들기\n",
    "conv = nn.Conv2d(1, 1, 5, stride = 1) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정\n",
    "\n",
    "# conv에 넣기 위해 input을 tensor로 만들기\n",
    "inputs = torch.Tensor(1, 1, 32, 64) # batch size : 1, input channel : 1, input size : 32 * 64\n",
    "\n",
    "# Convolution 이용하기\n",
    "output = conv(inputs)\n",
    "\n",
    "output.shape # 28 * 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 64, 32])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convolution 만들기\n",
    "conv = nn.Conv2d(1, 1, 3, stride = 1, padding = 1) # (인풋 채널, 아웃풋 채널, 필터 크기, Stride, padding) 설정\n",
    "\n",
    "# conv에 넣기 위해 input을 tensor로 만들기\n",
    "inputs = torch.Tensor(1, 1, 64, 32) # batch size : 1, input channel : 1, input size : 64 * 32\n",
    "\n",
    "# Convolution 이용하기\n",
    "output = conv(inputs)\n",
    "\n",
    "output.shape # 64 * 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Neuron(Perceptron)과 Convolution\n",
    " - Neuron과 Convolution의 관계를 살펴보자.\n",
    "### (1) Convolution을 구성하는 filter의 각 값들이 Perceptron의 weight로 들어간다.\n",
    " - ex) filter가 3 * 3의 크기라면 필터 안의 각 값들이 Perceptron의 weight로 9개의 class로 나뉘어져 들어간다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) Input 이미지에서 filter 크기만큼의 각 값들이 Perceptron에 각 클래스로 나뉘어져 들어가 연산된다.\n",
    " - ex) Input 이미지에서 3 * 3 크기의 각 값들이 Perceptron에 9개의 class로 나뉘어져 들어가 연산된다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### (3) 곱하고 더하는 연산이 진행 된 뒤, bias를 더한다. (filter도 bias를 가질 수 있음!)\n",
    " - ex) 1 + 3 + 1 + 1 + 2 = 8 => 8 + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Pooling\n",
    "### (1) Pooling이란?\n",
    " - Pooling 연산은 이미지의 사이즈를 줄이거나, fully-connected 연산을 대체하기 위해 사용한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) Max Pooling\n",
    " - Max Pooling의 Size를 2로 설정하면, 값들 중 2 * 2 사이즈 이내에서 가장 큰 값들을 취한다. \n",
    " - ex) \n",
    "\n",
    "<Max Pooling 전>\n",
    "\n",
    "| 1 | 9 | 3 | 7 |\n",
    "|---|:---:|---:|---:|\n",
    "| 4 | 5 | 2 | 8 |\n",
    "| 7 | 3 | 9 | 0 |\n",
    "| 1 | 2 | 3 | 3 |\n",
    "\n",
    "\n",
    "<Max Pooling 후>\n",
    "\n",
    "| 9 | 8 |\n",
    "|---|:---:|\n",
    "| 7 | 9 |\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### (3) Average Pooling\n",
    " - Average Pooling의 Size를 2로 설정하면, 값들 중 2 * 2 사이즈 이내에서 평균 값들을 취한다. \n",
    "\n",
    "<Average Pooling 전>\n",
    "\n",
    "| 1 | 1 | 2 | 2 |\n",
    "|---|:---:|---:|---:|\n",
    "| 1 | 1 | 2 | 2 |\n",
    "| 3 | 3 | 1 | 2 |\n",
    "| 3 | 3 | 1 | 4 |\n",
    "\n",
    "\n",
    "<Average Pooling 후>\n",
    "\n",
    "| 1 | 2 |\n",
    "|---|:---:|\n",
    "| 3 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. PyTorch의 MaxPool2d 도큐먼트\n",
    " - torch.nn.MaxPool2d(kernel_size, stride = None, padding = 0)\n",
    " - 다른 값들은 default 값이 잘 설정되어 있으므로 대체로 앞에서 배운 Size만 잘 설정하면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. CNN 모델 만들어보기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 12, 12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# conv에 넣기 위해 input을 tensor로 만들기\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "\n",
    "# Convolution 만들기\n",
    "conv1 = nn.Conv2d(1, 5, 5) # input 채널 : 1, output 채널 : 5, filter 크기 : 5\n",
    "\n",
    "# Pool 만들기\n",
    "pool = nn.MaxPool2d(2) # 2 * 2 사이즈 이내에서 가장 큰 값을 취함\n",
    "\n",
    "# Convolution 이용하기\n",
    "out = conv1(inputs) # input 이미지에 convolution을 돌린 결과가 out에 담김\n",
    "\n",
    "# Pool 이용하기\n",
    "out2 = pool(out) # out을 pool 한 결과가 out2에 담김\n",
    "\n",
    "out.size() # 24 * 24. Conv 해서 사이즈가 줄어듦!\n",
    "out2.size() # 12 * 12. Pool 해서 사이즈가 줄어듦!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 추가 내용 (몰라도 됨)\n",
    " - Convolution : 필터 값이 기존의 이미지와 얼마나 겹치는 가를 출력한다. Convolution은 필터를 상하좌우로 뒤집은 채로 돌린다!\n",
    " - Cross-correlation : 필터 값이 기존의 이미지와 얼마나 겹치는 가를 출력한다. Cross-correlation은 필터를 뒤집지 않은 채로 돌린다!\n",
    " - 이 내용은 딥러닝을 공부하면서 크게 알아두지는 않아도 되는 내용이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
