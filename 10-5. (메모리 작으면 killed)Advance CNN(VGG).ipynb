{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 오늘 배워볼 것은?\n",
    " - VGG Network 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. VGG-net 이란?\n",
    " - 참고 : http://blog.naver.com/PostView.nhn?blogId=laonple&logNo=221259295035\n",
    " - Oxford VGG(Visual Geometry Group)에서 만든 Network이다.\n",
    " - VGGNet은 Network의 깊이가 어떤 영향을 주는지 연구를 하기 위해서 설계된 Network이다. 따라서 Convolution kernel 사이즈를 한 사이즈로 정하고 Convolution의 개수를 늘리는 방식으로 테스트를 진행했다.\n",
    " - VGG-net은 전부 3 * 3 convolution, stride 1, padding 1으로 이루어져 있다.\n",
    " - 이론적으로는 5 * 5 kernel이나 3 * 3 kernel 2개나 성능적으로 동일하지만, VGGNet 팀이 테스트 한 결과 3 * 3 Kernel의 중첩이 더 좋았다. 그 이유는 non-linear 함수인 ReLU가 더 많이 들어가서 decision function이 더 잘 학습되기 때문이다. \n",
    " - 실험 결과 network의 깊이가 깊어질 수록 error가 내려간다. 하지만 19 layer부터는 성능이 나빠지는 것을 알 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. torchvision.models.vgg\n",
    " - torchvision의 모듈을 통해 vgg11 ~ vgg19까지 만들 수 있다.\n",
    " - 3(RGB) * 224 * 224의 input을 기준으로 만들도록 되어 있다.\n",
    " - 오늘 실습을 통해 input size가 다른 경우에 VGG를 적용해 보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. VGG Network 만들어 보기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 로드\n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 URL 지정하기 (PyTorch에서 ImageNet 챌린지 데이터셋을 기반으로 pretrain 시켜놓은 모델들)\n",
    "# 변수 선언\n",
    "__all__ = [\n",
    "  'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19',\n",
    "]\n",
    "\n",
    "# Pretrain 모델 URL\n",
    "model_urls = {\n",
    "  'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
    "  'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
    "  'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "  'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "  'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
    "  'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
    "  'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
    "  'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. VGG 네트워크 만들어 놓기\n",
    "class VGG(nn.Module): # nn.Module의 클래스를 상속받아서 이용한다.\n",
    "  def __init__(self, features, num_classes=1000, init_weights=True): # VGG 네트워크를 만들 때 초기 입력 파라미터로 Convolution(features), 분류 클래스 수, weight initialize 여부를 입력한다.\n",
    "    super(VGG, self).__init__()\n",
    "    self.features = features # 파라미터로 받은 값을 self.features로 설정.\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "    \n",
    "    # Classifier : VGG의 Classifier는 fully connected layer 3개로 이루어져 있다.\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Linear(512 * 7 * 7, 4096), # FC Layer 1. 512 * 7 * 7은 도큐먼트에 적혀있는 기본 사이즈이다. 이와 Image 사이즈가 다르거나, (custom layer 등을 이용해서) Convolution의 결과 output이 다른 경우 이 부분을 수정해 줘야 한다!\n",
    "      nn.ReLU(True),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(4096, 4096), # FC Layer 2\n",
    "      nn.ReLU(True),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(4096, num_classes), # FC Layer 3\n",
    "    )\n",
    "    \n",
    "    # weight initialize\n",
    "    if init_weights:\n",
    "      self._initialize_weights()\n",
    "      \n",
    "  # Forward 정의\n",
    "  def forward(self, x):\n",
    "    x = self.features(x) # Convolution\n",
    "    x = self.avgpool(x) # AvgPool\n",
    "    x = x.view(x.size(0), -1) # 일렬로 펼치기\n",
    "    x = self.classifier(x) # FC Layer\n",
    "    return x\n",
    "    \n",
    "  # 모듈 내용 별로 initialize weights 정의\n",
    "  def _initialize_weights(self):\n",
    "    for m in self.modules(): # 모듈을 하나씩 꺼내 봤을 때,\n",
    "      if isinstance(m, nn.Conv2d): # 만약 m이 Convolution이면\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu') # kaining_normal_로 filter의 weight를 초기화를 하라\n",
    "        if m.bias is not None: # VGG Net에서는 bias 값이 0이여야 하므로\n",
    "          nn.init.constant_(m.bias, 0) # m.bias를 0으로 초기화\n",
    "      elif isinstance(m, nn.BatchNorm2d): # 만약 m이 BatchNorm이면\n",
    "        nn.init.constant_(m.weight, 1) # weight는 전부 1로, bias는 전부 0으로 초기화\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "      elif isinstance(m, nn.Linear): # 만약 m이 nn.Linear이면\n",
    "        nn.init.normal_(m.weight, 0, 0.01) # 다음과 같이 초기화\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "  # Convolution Layer(feature)가 쌓이는 구조 정의\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = [] # 레이어를 쌓을 빈 리스트 선언\n",
    "    in_Channels = 3 # input channel 3\n",
    "    \n",
    "    for v in cfg: # cfg에서 하나씩 빼서 v로 이용\n",
    "      if v == 'M': # cfg에서 빼온 값이 M이면\n",
    "        layers += [nn.MaxPool2d(kernel_size=2, stride=2)] # MaxPool 추가\n",
    "      else: # cfg에서 빼온 값이 M이 아니면\n",
    "        conv2d = nn.Conv2d(in_Channels, v, kernel_size=3, padding=1) # v를 이용해 conv2d 정의\n",
    "        if batch_norm: # batch_norm = True인 경우\n",
    "          layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)] # 이 레이어를 layers 리스트에 추가!\n",
    "        else: # batch_norm = False인 경우\n",
    "          layers += [conv2d, nn.ReLU(inplace=True)] # 이 레이어를 layers 리스트에 추가!\n",
    "        in_channels = v # 중요! in_channels를 v로 바꿔준다. conv 레이어를 통과하고 나면 채널 수가 바뀌기 때문에, 다음 layer의 input에 들어갈 값을 바꿔줘야 한다.\n",
    "        \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convolution Layer 쌓을 내용 선언 (make_layers에 넣을 내용)\n",
    "cfg = { # cfg의 값에 따라 Convolution Layer가 쌓이게 된다.\n",
    "  'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # 이렇게 레이어를 쌓으면 Convolution 8 + Fully Connecyed 3가 나온다. => 11 => vgg11\n",
    "  'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'], # 10 + 3 = vgg 13\n",
    "  'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'], #1 3 + 3 = vgg 16\n",
    "  'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'], # 16 +3 = vgg 19\n",
    "  'custom' : [64,64,64,'M',128,128,128,'M',256,256,256,'M'] # 그 외 사용자가 임의로 설정 가능!\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 만들어 놓은 VGG 네트워크 이용하여 모델 만들기\n",
    "# Convolution Layer 만들기\n",
    "#conv = make_layers(cfg['custom'], batch_norm=True) # Convolution layer를 cfg 중 'custom'에 따라 쌓게 한다. batch norm = True로 설정.  => 이 줄이 있는 이유를 모르겠음\n",
    "CNN = VGG(make_layers(cfg['custom']), num_classes=10, init_weights=True) # VGG의 파라미터로 Convolution layer(feature), class 개수, weights initialize를 설정하여 VGG 모델(CNN)을 만든다.\n",
    "CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. VGG Network를 실제 데이터에 이용하기 전에\n",
    " - 주피터노트북을 Text로 만들어서 이름을 vgg.py로 설정하고, Pytorch 홈페이지의 Torchvision.model에 있는 VGG를 복사해서 붙여 넣는다.\n",
    " - 학습할 위치의 같은 폴더 안에 이 파일이 있어야 VGG를 불러와서 사용할 수 있다!\n",
    " - 위의 방법이 귀찮다면 그냥 import torchvision.models.vgg as vgg로도 사용 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. CIFAR10 데이터에 VGG 적용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 비스돔 이용\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\") # main에 켜져있는게 있다면 다 끈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. loss tracker 정의\n",
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "  vis.line(X=num,\n",
    "           Y=loss_value,\n",
    "           win = loss_plot,\n",
    "           update = 'append'\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. device 및 seed 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 5. 데이터 정의\n",
    "# transform\n",
    "transform = transforms.Compose(\n",
    "  [transforms.ToTensor(), # tensor 화\n",
    "   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # Normalize\n",
    "\n",
    "# 데이터 셋 불러오기\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=0)\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=0)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck   dog horse truck\n"
     ]
    }
   ],
   "source": [
    "# 6. visdom에서 이미지 확인\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "  plt.show()\n",
    "  \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "vis.images(images/2 + 0.5) # visdom에 이미지를 띄운다.\n",
    "\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. VGG 네트워크 : 라이브러리 로드\n",
    "#import vgg   # 오타 같음\n",
    "import torchvision.models.vgg as vgg # vgg.py를 만들기 귀찮은 경우 이렇게 라이브러리를 불러서 이용해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. VGG 네트워크 : Convolution Layer 쌓을 내용 선언 (make_layers에 넣을 내용)\n",
    "cfg = [32, 32, 'M', 64, 64, 128, 128, 128, 'M', 256, 256, 256, 512, 512, 512, 'M'] # convolution 13 + FC Layer 3 => vgg16!\n",
    "# 이 네트워크의 아웃풋을 계산해보면, 32 * 32를 MaxPool 3번 하므로 32 => 16 => 8 => 4가 된다. 즉 아웃풋은 4 * 4 이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. VGG 네트워크 : VGG 네트워크 만들어 놓기\n",
    "class VGG(nn.Module):\n",
    "  def __init__(self, features, num_classes=1000, init_weights=True): # 파라미터로 Convolution(features), class 수(초기값은 1000이지만, 나중에 10으로 넣을 것임), weight initialize 설정.\n",
    "    super(VGG, self).__init__()\n",
    "    self.features = features\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Linear(512 * 4 * 4, 4096), # 수정! Conv의 아웃풋을 계산 해 보면 4 * 4 이므로 거기에 맞게 수정했다.\n",
    "      nn.ReLU(True),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(4096, 4096),\n",
    "      nn.ReLU(True),\n",
    "      nn.Dropout(),\n",
    "      nn.Linear(4096, num_classes),\n",
    "    )\n",
    "    if init_weights:\n",
    "      self._initialize_weights()\n",
    "      \n",
    "  def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "    \n",
    "  def _initialize_weights(self):\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.constant_(m.bias, 0)\n",
    "      elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "      elif isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, 0, 0.01)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 10. VGG 네트워크 : 만들어 놓은 VGG 네트워크 이용하여 모델 만들기\n",
    "vgg16 = VGG(vgg.make_layers(cfg), 10, True).to(device) # Convolution(feature), Class 수, weight initialize를 설정해서 모델 정의. \n",
    "\n",
    "# 만든 VGG 모델에 오류 없나 테스트하기\n",
    "a = torch.Tensor(1, 3, 32, 32).to(device)\n",
    "out = vgg16(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. VGG 네트워크 : Loss, Optimizer, Lr 설정\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(vgg16.parameters(), lr=0.005, momentum=0.9)\n",
    "\n",
    "# NEW! lr을 고정해 놓지 않고 학습에 따라 lr을 조금씩 감소시키며 학습하는 방법이다. 정밀한 학습에 도움이 된다.\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9) # 5번의 step마다 Optimizer의 lr에 0.9를 곱해 준다.\n",
    "\n",
    "# loss를 plot으로 만들기\n",
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(), opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloudera/.local/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    30] loss:   2\n",
      "[1,    60] loss:   2\n",
      "[1,    90] loss:   2\n",
      "[2,    30] loss:   2\n",
      "[2,    60] loss:   2\n",
      "[2,    90] loss:   2\n",
      "[3,    30] loss:   2\n",
      "[3,    60] loss:   2\n",
      "[3,    90] loss:   2\n",
      "[4,    30] loss:   2\n",
      "[4,    60] loss:   2\n",
      "[4,    90] loss:   2\n",
      "[5,    30] loss:   2\n",
      "[5,    60] loss:   2\n",
      "[5,    90] loss:   2\n",
      "[6,    30] loss:   1\n",
      "[6,    60] loss:   1\n",
      "[6,    90] loss:   1\n",
      "[7,    30] loss:   1\n",
      "[7,    60] loss:   1\n",
      "[7,    90] loss:   1\n",
      "[8,    30] loss:   1\n",
      "[8,    60] loss:   1\n",
      "[8,    90] loss:   1\n",
      "[9,    30] loss:   1\n",
      "[9,    60] loss:   1\n",
      "[9,    90] loss:   1\n",
      "[10,    30] loss:   1\n",
      "[10,    60] loss:   1\n",
      "[10,    90] loss:   1\n",
      "[11,    30] loss:   1\n",
      "[11,    60] loss:   1\n",
      "[11,    90] loss:   1\n",
      "[12,    30] loss:   1\n",
      "[12,    60] loss:   1\n",
      "[12,    90] loss:   1\n",
      "[13,    30] loss:   1\n",
      "[13,    60] loss:   1\n",
      "[13,    90] loss:   1\n",
      "[14,    30] loss:   1\n",
      "[14,    60] loss:   1\n",
      "[14,    90] loss:   1\n",
      "[15,    30] loss:   1\n",
      "[15,    60] loss:   1\n",
      "[15,    90] loss:   1\n",
      "[16,    30] loss:   1\n",
      "[16,    60] loss:   1\n",
      "[16,    90] loss:   1\n",
      "[17,    30] loss:   1\n",
      "[17,    60] loss:   1\n",
      "[17,    90] loss:   1\n",
      "[18,    30] loss:   1\n",
      "[18,    60] loss:   1\n",
      "[18,    90] loss:   1\n",
      "[19,    30] loss:   1\n",
      "[19,    60] loss:   1\n",
      "[19,    90] loss:   1\n",
      "[20,    30] loss:   1\n",
      "[20,    60] loss:   1\n",
      "[20,    90] loss:   1\n",
      "[21,    30] loss:   1\n",
      "[21,    60] loss:   1\n",
      "[21,    90] loss:   1\n",
      "[22,    30] loss:   1\n",
      "[22,    60] loss:   1\n",
      "[22,    90] loss:   1\n",
      "[23,    30] loss:   1\n",
      "[23,    60] loss:   1\n",
      "[23,    90] loss:   1\n",
      "[24,    30] loss:   1\n",
      "[24,    60] loss:   1\n",
      "[24,    90] loss:   1\n",
      "[25,    30] loss:   0\n",
      "[25,    60] loss:   0\n",
      "[25,    90] loss:   0\n",
      "[26,    30] loss:   0\n",
      "[26,    60] loss:   0\n",
      "[26,    90] loss:   0\n",
      "[27,    30] loss:   0\n",
      "[27,    60] loss:   0\n",
      "[27,    90] loss:   0\n",
      "[28,    30] loss:   0\n",
      "[28,    60] loss:   0\n",
      "[28,    90] loss:   0\n",
      "[29,    30] loss:   0\n",
      "[29,    60] loss:   0\n",
      "[29,    90] loss:   0\n",
      "[30,    30] loss:   0\n",
      "[30,    60] loss:   0\n",
      "[30,    90] loss:   0\n",
      "[31,    30] loss:   0\n",
      "[31,    60] loss:   0\n",
      "[31,    90] loss:   0\n",
      "[32,    30] loss:   0\n",
      "[32,    60] loss:   0\n",
      "[32,    90] loss:   0\n",
      "[33,    30] loss:   0\n",
      "[33,    60] loss:   0\n",
      "[33,    90] loss:   0\n",
      "[34,    30] loss:   0\n",
      "[34,    60] loss:   0\n",
      "[34,    90] loss:   0\n",
      "[35,    30] loss:   0\n",
      "[35,    60] loss:   0\n",
      "[35,    90] loss:   0\n",
      "[36,    30] loss:   0\n",
      "[36,    60] loss:   0\n",
      "[36,    90] loss:   0\n",
      "[37,    30] loss:   0\n",
      "[37,    60] loss:   0\n",
      "[37,    90] loss:   0\n",
      "[38,    30] loss:   0\n",
      "[38,    60] loss:   0\n",
      "[38,    90] loss:   0\n",
      "[39,    30] loss:   0\n",
      "[39,    60] loss:   0\n",
      "[39,    90] loss:   0\n",
      "[40,    30] loss:   0\n",
      "[40,    60] loss:   0\n",
      "[40,    90] loss:   0\n",
      "[41,    30] loss:   0\n",
      "[41,    60] loss:   0\n",
      "[41,    90] loss:   0\n",
      "[42,    30] loss:   0\n",
      "[42,    60] loss:   0\n",
      "[42,    90] loss:   0\n",
      "[43,    30] loss:   0\n",
      "[43,    60] loss:   0\n",
      "[43,    90] loss:   0\n",
      "[44,    30] loss:   0\n",
      "[44,    60] loss:   0\n",
      "[44,    90] loss:   0\n",
      "[45,    30] loss:   0\n",
      "[45,    60] loss:   0\n",
      "[45,    90] loss:   0\n",
      "[46,    30] loss:   0\n",
      "[46,    60] loss:   0\n",
      "[46,    90] loss:   0\n",
      "[47,    30] loss:   0\n",
      "[47,    60] loss:   0\n",
      "[47,    90] loss:   0\n",
      "[48,    30] loss:   0\n",
      "[48,    60] loss:   0\n",
      "[48,    90] loss:   0\n",
      "[49,    30] loss:   0\n",
      "[49,    60] loss:   0\n",
      "[49,    90] loss:   0\n",
      "[50,    30] loss:   0\n",
      "[50,    60] loss:   0\n",
      "[50,    90] loss:   0\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 12. VGG 네트워크 : 학습하기\n",
    "print(len(trainloader))\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step() # epoch이 5번 돌 때마다 lr이 0.9배씩 줄어든다.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = vgg16(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29: # 30회마다 loss tracker!\n",
    "            loss_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch * len(trainloader)]))  \n",
    "            print('[%d, %5d] loss: %3.f' %(epoch+1, i+1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n",
      "Predicted:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "# 13. VGG 네트워크 : 시각화를 통해 Test 데이터 잘 맞추나 확인하기\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# GT 이미지 4개 출력해보기\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# GT와 outputs의 결과가 같나 확인하기\n",
    "outputs = vgg16(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 9 %\n"
     ]
    }
   ],
   "source": [
    "# 14. VGG 네트워크 : Test 셋으로 모델 평가하기\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "  for data in testloader:\n",
    "    imgaes, labels = data\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = vgg16(images)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    total += labels.size(0)\n",
    "    \n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' %(100*correct / total)) # 정확도 76%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
