{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 들어가기 전에\n",
    " - device : Cuda를 사용중이면 현재 device는 Cuda이고, 아니면 현재 device는 CPU 이다.\n",
    " - to(device) : 이 명령을 작성해야 하는 이유는, Cuda에서 연산을 진행할 때 Torch tensor가 아닌 Torch Cuda tensor를 이용해야 하기 때문에 이 명령어를 작성한다.\n",
    " - print(device) : 현재 사용중인 device 확인 가능!\n",
    " - print(torch.cuda.is_available()) : 현재 Cuda 사용 가능한지 확인 가능!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CNN의 학습 단계\n",
    " - 라이브러리 로드\n",
    " - GPU 사용 설정 및 random value를 위한 seed 설정\n",
    " - 하이퍼파라미터 설정(LR, epoch, batch_size 등)\n",
    " - 데이터셋 로드 및 학습에 편하게 Loader로 만들기\n",
    " - CNN 모델 만들어 두기\n",
    " - Loss와 Optimizer 선택\n",
    " - CNN 모델 학습 및 loss 확인\n",
    " - 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 우리가 실습할 CNN 구조\n",
    "### (1) Input\n",
    " - MNIST의 이미지 데이터\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) CNN\n",
    " #### 1) Layer 1\n",
    "  - Convolution\n",
    "  - ReLU\n",
    "  - MaxPool\n",
    "  \n",
    " #### 2) Layer 2\n",
    "  - Convolution\n",
    "  - ReLU\n",
    "  - MaxPool\n",
    "  \n",
    " #### 3) FC Layer(Fully Connected Layer)\n",
    "  - view : FC를 위해 Flatten을 시켜 직선으로 쫙 펼치는 과정\n",
    "  - FC\n",
    "\n",
    "<br>\n",
    "\n",
    "### (3) Cross Entropy Loss\n",
    " - SoftMax\n",
    " - NLL loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. MNIST CNN 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GPU 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # cuda가 사용 가능한 상황이면 cuda를 쓰고, 아니면 CPU를 사용\n",
    "\n",
    "torch.manual_seed(777) # random value 고정!\n",
    "if device == 'cuda': # cuda일 때\n",
    "    torch.cuda.manual_seed_all(777) # random value 고정!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 하이퍼 파라미터 설정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 데이터 셋 가져오기\n",
    "mnist_train = dsets.MNIST(root = 'MNIST_data/', train = True, transform = transforms.ToTensor(), download = True) # train = True를 설정해서 트레인용 데이터를 받아아고, transform으로 input 데이터를 tensor화 하고, download로 다운 받아서 이용\n",
    "mnist_test = dsets.MNIST(root = 'MNIST_data/', train = False, transform = transforms.ToTensor(), download = True) # train = False를 설정해서 테스트용 데이터를 받아온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 데이터 로더\n",
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, batch_size = batch_size, shuffle = True, drop_last = True) # 데이터 셋, 배치 사이즈, 데이터 섞는 여부, drop last 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. CNN 모델 만들기\n",
    "class CNN(torch.nn.Module): # Pytorch의 모듈을 상속받아 CNN 클래스를 설정한다.\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__() # 주의! 필수 작업!\n",
    "\n",
    "        # Layer 1\n",
    "        self.layer1 = torch.nn.Sequential( # Sequential로 레이어를 쌓을 수 있다.\n",
    "        torch.nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1), # Convolution\n",
    "        torch.nn.ReLU(), # ReLU\n",
    "        torch.nn.MaxPool2d(kernel_size = 2, stride = 2)) # MaxPool\n",
    "    \n",
    "        # Layer 2\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "      \n",
    "        # FC Layer\n",
    "        self.fc = torch.nn.Linear(7*7*64, 10, bias = True) # 앞 과정을 거친 size를 미리 계산해 보면 64 채널의 7 * 7 크기가 나온다. 그걸 FC를 통해 Flatten으로 직선으로 쫙 펼치게 된다. FC의 output은 10개(0 ~ 9) 이다.\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight) # FC Layer의 weight를 xavier로 초기화\n",
    "   \n",
    "    # 모델의 forward 진행 과정\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x) # Layer 1 통과\n",
    "        out = self.layer2(out) # Layer 2 통과\n",
    "        out = out.view(out.size(0), -1) # FC Layer을 위해 Flatten으로 한 줄(-1)으로 펼치기.\n",
    "        out = self.fc(out) # FC Layer 통과\n",
    "        return out\n",
    "    \n",
    "# 모델 설정\n",
    "model = CNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n"
     ]
    }
   ],
   "source": [
    "# 7. Loss와 Optimizer 설정\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device) # Cross Entropy Loss 사용\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) # Adam Optimizer 사용\n",
    "\n",
    "total_batch = len(data_loader) # batch 몇개 인지 확인\n",
    "print('Learning started. It takes sometime.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1 cost = 0.22395089268684387\n",
      "[Epoch:    2 cost = 0.06211347132921219\n",
      "[Epoch:    3 cost = 0.04482545703649521\n",
      "[Epoch:    4 cost = 0.035523492842912674\n",
      "[Epoch:    5 cost = 0.029017852619290352\n",
      "[Epoch:    6 cost = 0.024802125990390778\n",
      "[Epoch:    7 cost = 0.020738985389471054\n",
      "[Epoch:    8 cost = 0.01811862364411354\n",
      "[Epoch:    9 cost = 0.015076704323291779\n",
      "[Epoch:   10 cost = 0.012611476704478264\n",
      "[Epoch:   11 cost = 0.01029976923018694\n",
      "[Epoch:   12 cost = 0.010091177187860012\n",
      "[Epoch:   13 cost = 0.008734307251870632\n",
      "[Epoch:   14 cost = 0.007107528392225504\n",
      "[Epoch:   15 cost = 0.00541576137766242\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# 8. 학습 시작!\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "  \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device) # 학습할 이미지\n",
    "        Y = Y.to(device) # 학습할 라벨\n",
    "\n",
    "        hypothesis = model(X) # 모델 이용!\n",
    "        cost = criterion(hypothesis, Y) # cost 계산\n",
    "\n",
    "        # BP\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        avg_cost += cost / total_batch\n",
    "    \n",
    "    print('[Epoch: {:4} cost = {:9}'.format(epoch + 1, avg_cost))\n",
    "    \n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9871999621391296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloudera/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/cloudera/.local/lib/python3.6/site-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "# 9. 모델 평가\n",
    "with torch.no_grad(): # Test할 때는 학습을 안함! No gradient\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device) # X_test 값을 불러와서 모델에 한 번에 집어넣으려고 쫙 펼침\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "  \n",
    "    prediction = model(X_test) # 모델에 X_test를 한번에 다 집어넣음! (No batch)\n",
    "  \n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item()) # 98.5 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 더 생각해보기\n",
    " - 레이어를 더 깊게 쌓으면 어떻게 될까? 정확도가 더 높아지지 않을까? 레이어를 더 깊게 쌓아보자!\n",
    "### (1) Input\n",
    " - MNIST의 이미지 데이터\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) CNN\n",
    " #### 1) Layer 1\n",
    "  - Convolution\n",
    "  - ReLU\n",
    "  - MaxPool\n",
    "  \n",
    " #### 2) Layer 2\n",
    "  - Convolution\n",
    "  - ReLU\n",
    "  - MaxPool\n",
    "\n",
    " #### 3) Layer 3\n",
    "  - Convolution\n",
    "  - ReLU\n",
    "  - MaxPool\n",
    "\n",
    " #### 4) FC Layer 1 (Fully Connected Layer)\n",
    "  - view : FC를 위해 Flatten을 시켜 직선으로 쫙 펼치는 과정\n",
    "  - FC 1\n",
    "\n",
    " #### 5) FC Layer 2 (Fully Connected Layer)\n",
    "  - ReLU\n",
    "  - FC 2\n",
    "\n",
    "<br>\n",
    "\n",
    "### (3) Cross Entropy Loss\n",
    " - SoftMax\n",
    " - NLL loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MNIST 더 깊은 CNN 실습\n",
    "\n",
    "```python\n",
    "class CNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "\n",
    "    # Layer 1\n",
    "    self.layer1 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "    # Layer 2\n",
    "    self.layer2 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "\n",
    "    # Layer 3\n",
    "    self.layer3 = torch.nn.Sequential(\n",
    "      torch.nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "      torch.nn.ReLU(),\n",
    "      torch.nn.MaxPool2d(Kernel_size = 2, stride = 2))\n",
    "\n",
    "    # FC Layer 1\n",
    "    self.fc1 = torch.nn.Linear(3 * 3 * 128, 625)\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    # FC Layer 2\n",
    "    self.fc2 = torch.nn.Linear(625, 10, bias = True)\n",
    "\n",
    "    torch.nn.init.xavier_uniform_(self. fc1.weight)\n",
    "    torch.nn.init.xavier_uniform_(self. fc2.weight)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    out = self.layer1(x)\n",
    "    out = self.layer2(out)\n",
    "    out = self.layer3(out)\n",
    "    \n",
    "    out = out.view(out.size(0), -1)\n",
    "    \n",
    "    out = self.fc1(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.fc2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MNIST 더 깊은 CNN 실습 결과\n",
    " - Accuracy가 0.97이 나왔다. 더 깊게 쌓았는데 정확도는 더 낮아졌다!\n",
    " - 결론 : 모델을 깊게 쌓는 것도 중요하지만, 모델의 아키텍쳐를 공부하며 효율적으로 쌓는 것이 더 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 꿀팁\n",
    " - 모델을 만들고서 학습시키기 전에, 모델이 오류없이 잘 만들어 졌나 확인하는 절차가 있으면 좋다!\n",
    " - 모델의 각 레이어의 인풋, 아웃풋 값을 잘 설정해야 오류가 없다. Convolution을 하고 나서, Pool을 하고 나서의 Output을 잘 계산해서 다음 레이어의 인풋 값 등을 잘 설정해줘야 오류가 없다.\n",
    "\n",
    "```python\n",
    "model = CNN().to(device)\n",
    "value = torch.Tensor(1, 1, 28, 28).to(device)\n",
    "print( (model(value)).shape )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
