{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 들어가기 전에\n",
    " - 이번 시간에는 지난시간 강의에 이어, 내 사진들을 분류하는 CNN 모델을 만들 것이다!\n",
    " - 모델을 저장하고 다시 불러오는 법을 배울 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pretrained model이란?\n",
    " - Pretrained model이란, 이미 학습을 진행한 모델을 불러와서 이용하는 것이다.\n",
    " - 모델을 이용할 때마다 학습시키는 것 보다, 학습 된 모델을 불러와서 이용하는게 더 시간적으로 좋기 때문!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pretrained model 이용 방법\n",
    "### <기존 방법>\n",
    "#### (1) CNN 모델의 구조를 미리 만들어 둔다.\n",
    "#### (2) 그 구조를 변수에 담는다.\n",
    "#### (3) 변수(모델)에 Train 데이터를 통해 학습시킨다.\n",
    " \n",
    "<br>\n",
    " \n",
    "### <Pretrained 된 모델 불러와서 이용하기>\n",
    "#### (1) (이용할 Pretrained 모델과 동일한) CNN 모델의 구조를 미리 만들어 둔다.\n",
    "#### (2) 그 구조를 변수에 담는다.\n",
    "#### (3) 변수(모델)에 Pretrained 모델을 불러온다.\n",
    "  - Pretrained 모델을 이용하는 것은 미리 학습 된 모델을 이용하는 것이다. 즉, '모델에 Train 데이터로 학습 시키는 과정을 생략하는 것'이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CNN 모델 구성하기\n",
    "### (1) Input\n",
    " - 나의 이미지\n",
    "\n",
    "<br>\n",
    "\n",
    "### (2) CNN 레이어\n",
    "#### 1) Layer 1\n",
    " - Convolution\n",
    " - ReLU\n",
    " - MaxPool\n",
    "\n",
    "#### 2) Layer 2\n",
    " - Convolution\n",
    " - ReLU\n",
    " - MaxPool\n",
    " \n",
    "#### 3) FC Layer (Fully-Connected Layer)\n",
    " - view (FC를 위한 작업)\n",
    " - FC1\n",
    " - ReLU\n",
    " - FC2\n",
    " \n",
    "<br>\n",
    "\n",
    "### (3) Cross Entropy Loss\n",
    " - SoftMax\n",
    " - NLL loss\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 구성한 CNN 모델 코드로 작성해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Input Image : 3 * 64 * 128 (RGB 3채널 * Height * Width)\n",
    "\n",
    "# 2. Layer 1\n",
    "Convolution layer = (in_c=3, out_c=6, kernel_size = 5, stride=1) # RGB의 3 채널을 받아서, output은 6채널로!\n",
    "MaxPool layer = (kernel_size=2, stride=2)\n",
    "\n",
    "# 3. Layer 2\n",
    "Convolution layer = (in_c=6, out_c=16, kernel_size=5, stride=1) # 6 채널을 받아서, output은 16채널로!\n",
    "MaxPool layer = (kernel_size=2, stride=2)\n",
    "\n",
    "# 4. FC Layer\n",
    "view # Layer 2 까지 거친 output은 [16, 13, 29] 이다. FC를 이용하기 전에 직선으로 펼치기 위해 batch_size * [16, 13, 29]를 한다. => batch_size * [6032]\n",
    "Fully_Connect layer # input으로 6032를 받아서, output은 120으로!\n",
    "Fully_Connect layer # input으로 120을 받아서, output은 2로! Grey인지 Red인지 구분하는 Binary classification이기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 전체 코드 작성해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GPU 사용 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777) # 랜덤 값 Seed 고정\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 데이터 로드\n",
    "trans = transforms.Compose([\n",
    "  transforms.ToTensor() # 불러올 때 Tensor로 바꿔서 불러옴\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='./custom_data/train_data', transform = trans) # 지난 시간에 만들어 둔 train_data!\n",
    "\n",
    "data_loader = DataLoader(dataset = train_data, batch_size = 8, shuffle = True, num_workers=2) # Data Loader 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CNN 모델 만들어 놓기\n",
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    # Layer 1\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Conv2d(3, 6, 5), # RGB 3채널 입력, 6채널 출력, 필터 5\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2),\n",
    "    )\n",
    "    \n",
    "    # Layer 2\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Conv2d(6, 16, 5), # 6채널 입력, 16채널 출력, 필터 5\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(2),\n",
    "    )\n",
    "    \n",
    "    # FC Layer\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Linear(16 * 13 * 29, 120), # FC1\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(120, 2) # FC2\n",
    "    )\n",
    "  \n",
    "  # 모델의 forward 정의\n",
    "  def forward(self, x):\n",
    "    out = self.layer1(x) # Layer 1 통과\n",
    "    # print(out.shape) # 꿀팁! 이런 방식으로 모델이 forward할 때 점차 바뀌는 output의 shape을 체크할 수 있다. 나중에 추가적으로 모델의 레이어 구조 등을 변형하고 싶을 때 이 방법이 유용하다. 이 코드로 shape만 확인하고 바로 꼭 지워주는 센스! \n",
    "    out = self.layer2(out) # Layer 2 통과\n",
    "    # print(out.shape)\n",
    "    out = out.view(out.shape[0], -1) # Flatten으로 펼치기\n",
    "    # print(out.shape)\n",
    "    out = self.layer3(out) # FC1 & FC 2 통과\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (생략 가능) 5. CNN 모델을 오류 없이 만들었는지 테스트 해보기\n",
    "net = CNN().to(device)\n",
    "test_input = (torch.Tensor(3, 3, 64, 128)).to(device)\n",
    "test_out = net(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Optimizer와 Loss 설정\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.00005)\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "total_batch = len(data_loader)\n",
    "epochs = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:1] cost = 0.6340084671974182\n",
      "[Epoch:2] cost = 0.37498798966407776\n",
      "[Epoch:3] cost = 0.11253253370523453\n",
      "[Epoch:4] cost = 0.035550229251384735\n",
      "[Epoch:5] cost = 0.01641702465713024\n",
      "[Epoch:6] cost = 0.009223982691764832\n",
      "[Epoch:7] cost = 0.00570299755781889\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# 7. 모델 학습 시작!\n",
    "for epoch in range(epochs):\n",
    "  avg_cost = 0.0\n",
    "  for num, data in enumerate(data_loader):\n",
    "    imgs, labels = data\n",
    "    \n",
    "    imgs = imgs.to(device) # 독립 변수\n",
    "    labels = labels.to(device) # 종속 변수\n",
    "    \n",
    "    out = net(imgs) # 모델에 독립 변수를 넣어 Prediction 얻기\n",
    "    loss = loss_func(out, labels)\n",
    "    \n",
    "    # BP\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    avg_cost += loss / total_batch\n",
    "    \n",
    "  print('[Epoch:{}] cost = {}'.format(epoch+1, avg_cost))\n",
    "print('Learning Finished!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 학습된 CNN 모델 저장하기\n",
    "torch.save(net.state_dict(), \"./model/model.pth\") # 경로를 지정해서 학습된 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Pretrained 된 CNN 모델 : 불러와서 이용하기\n",
    "\n",
    "'''\n",
    "<기존 방법>\n",
    " (1) CNN 모델의 구조를 미리 만들어 둔다.\n",
    " (2) 그 구조를 변수에 담는다.\n",
    " (3) 변수(모델)에 Train 데이터를 통해 학습시킨다.\n",
    " \n",
    "<Pretrained 된 모델 불러와서 이용하기>\n",
    " (1) (이용할 Pretrained 모델과 동일한) CNN 모델의 구조를 미리 만들어 둔다.\n",
    " (2) 그 구조를 변수에 담는다.\n",
    " (3) 변수(모델)에 Pretrained 모델을 불러온다.\n",
    "  - Pretrained 모델을 이용하는 것은 미리 학습 된 모델을 이용하는 것이다. 즉, '모델에 Train 데이터로 학습 시키는 과정을 생략하는 것'이다.\n",
    "'''\n",
    "\n",
    "new_net = CNN().to(device) # 이용할 Pretrained 모델과 동일한 구조를 가진 모델!\n",
    "new_net.load_state_dict(torch.load('./model/model.pth')) # 거기에 Pretrained 모델을 담는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (생략 가능) 10. Pretrainted 된 CNN 모델 : 구조 확인\n",
    "print(net.layer1[0])\n",
    "print(new_net.layer1[0])\n",
    "\n",
    "print(net.layer1[0].weight[0][0][0])\n",
    "print(new_net.layer1[0].weight[0][0][0])\n",
    "\n",
    "net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Pretrained 된 CNN 모델 : 테스트 데이터 로드 (기존과 동일)\n",
    "trans = torchvision.transforms.Compose([\n",
    "  transforms.Resize((64, 128)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(root='./custom_data/test_data', transform = trans) # test data 로드\n",
    "\n",
    "test_set = DataLoader(dataset = test_data, batch_size = len(test_data)) # DataLoader 이용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 12. Pretrainted 된 CNN 모델 : 모델 평가 (기존과 동일)\n",
    "with torch.no_grad(): # 모델 평가시에는 Gradient Descent 안함!\n",
    "    for num, data in enumerate(test_set):\n",
    "        imgs, label = data\n",
    "        imgs = imgs.to(device)\n",
    "        label = label.to(device)\n",
    "    \n",
    "        prediction = net(imgs)\n",
    "    \n",
    "        correct_prediction = torch.argmax(prediction, 1) == label\n",
    "    \n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
