{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 들어가기 전에\n",
    " - 주피터 노트북을 메모장으로 켜서 제목을 resnet.py으로 하고 resnet 도큐먼트를 붙여 넣는다.\n",
    " - resnet을 이용할 폴더의 같은 위치에 resnet.py가 있어야 실행 된다!\n",
    " - 이전에 배웠던 vgg에서 모델을 resnet으로 바꾼 채로 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CIFAR10에 ResNet 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 라이브러리 로드\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Visdom 이용  # 터미널에서 python3 -m visdom.server 실행, 브라우저에서 http://localhost:8097 실행\n",
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Value(Accuracy, Loss) tracker\n",
    "def value_tracker(value_plot, value, num):\n",
    "    vis.line(X=num,\n",
    "             Y=value,\n",
    "             win=value_plot,\n",
    "             update='append'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[125.30691805 122.95039414 113.86538318] [62.99321928 62.08870764 66.70489964]\n",
      "[0.49139968 0.48215841 0.44653091] [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "# 4. GPU 설정\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# 팁! Normalize 값 계산하는 방법 1 : 데이터 로드\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "\n",
    "# 팁! Normalize 값 계산하는 방법 2 : 계산\n",
    "'''\n",
    "이전의 VGG 예시에서는 transform을 이용 할 때 Normalize 값에 0.5와 같은 값을 무작정 넣었는데,\n",
    "이번에는 Normalize를 직접 계산해서 transform 할 때 계산 값을 넣어 보자!\n",
    "'''\n",
    "\n",
    "train_data_mean = trainset.data.mean( axis = (0, 1, 2) ) # 데이터 셋의 각 축에 대한 평균 계산. # 버전 오류 발생  AttributeError: 'CIFAR10' object has no attribute 'train_data'. \n",
    "train_data_std = trainset.data.std( axis = (0, 1, 2) ) # 데이터 셋의 가 축에 대한 std 계산\n",
    "print(train_data_mean, train_data_std)\n",
    "\n",
    "train_data_mean = train_data_mean / 255 # 앞에서 구한 값을 255로 나눠준다.\n",
    "train_data_std = train_data_std / 255 # 앞에서 구한 값을 255로 나눠준다.\n",
    "print(train_data_mean, train_data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 5. 데이터 로드\n",
    "transform_train = transforms.Compose([\n",
    "  transforms.RandomCrop(32, padding=4), # padding을 4로 두른 후, 32만큼 랜덤하게 crop한다. 데이터 셋의 형태를 변형시키는 데 좋은 방법!\n",
    "  transforms.ToTensor(), # 텐서화\n",
    "  transforms.Normalize(train_data_mean, train_data_std) # 앞에서 직접 구한 Normalize 값으로 Normalize 해 준다.\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=0)\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ResNet 네트워크 구축\n",
    "# 라이브러리 로드\n",
    "import resnet\n",
    "import torchvision.models.resnet # resnet.py를 저장해서 이용하는 것이 아닌, 이렇게 라이브러리를 불러와서 이용해도 된다.\n",
    "\n",
    "# resnet 기본 설정\n",
    "conv1x1 = resnet.conv1x1\n",
    "Bottleneck = resnet.Bottleneck\n",
    "BasicBlock = resnet.BasicBlock\n",
    "\n",
    "# ResNet 네트워크 구축 해 놓기\n",
    "# 변형!은 기존의 ResNet 예제에서 변형 한 것을 뜻한다.\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 16 # 변형! 이번에는 inplanes을 16으로 설정했다.\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False) # input 3채널, output 16채널 \n",
    "    \n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1) # 변형! layer의 사이즈를 64-> 16과 같이 간소화. stride도 바꿈\n",
    "        self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\n",
    "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\n",
    "    \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(128 * block.expansion, num_classes) # input : 128 * block.expansion = 512, output : 10\n",
    "    \n",
    "        # 변형 x\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        # 변형 x  \n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "          \n",
    "    # 변형 x        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "    \n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "              layers.append(block(self.inplanes, planes))\n",
    "      \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # [1, 16, 32, 32]\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        x = self.layer1(x) # [1, 128, 32, 32]\n",
    "        x = self.layer2(x) # [1, 256, 32, 32]\n",
    "        x = self.layer3(x) # [1, 512, 16, 16]\n",
    "        x = self.layer4(x) # [1, 1024, 8, 8]\n",
    "    \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. ResNet 모델 이용하기!\n",
    "resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 10, True).to(device) # Bottleneck과 [3, 4, 6, 3]을 설정하면 resnet 50을 만들 수 있다.\n",
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0338,  0.0122,  0.0168, -0.0428, -0.0382, -0.0435, -0.0441,  0.0176,\n",
      "         -0.0341, -0.0110]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 8. ResNet 모델에 오류 없나 테스트 해보기\n",
    "a = torch.Tensor(1, 3, 32, 32).to(device)\n",
    "out = resnet50(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Loss, Optimizer, LR\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(resnet50.parameters(), lr = 0.1, momentum = 0.9, weight_decay = 5e-4)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Loss와 Acc로 Plot으로 만들기\n",
    "loss_plt = vis.line(Y=torch.Tensor(1).zero_(), opts=dict(title='loss_tracker', legend=['loss'], showlegend=True))\n",
    "acc_plt = vis.line(Y=torch.Tensor(1).zero_(), opts=dict(title='Accuracy', legend=['Acc'], showlegend=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Accuracy 체크하는 함수\n",
    "def acc_check(net, test_set, epoch, save=1):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_set:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = net(images)\n",
    "      \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "      \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "      \n",
    "    acc = (100 * correct / total)\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' %acc)\n",
    "    if save: # save를 True로 설정 할 경우, 지정 된 폴더에 epoch 별 정확도를 저장할 수 있다.\n",
    "        torch.save(net.state_dict(), \"./model/model_epoch_{}_acc_{}.pth\".format(epoch, int(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n",
      "[1,    30] loss: 2.058\n",
      "[1,    60] loss: 1.902\n",
      "[1,    90] loss: 1.878\n",
      "[1,   120] loss: 1.891\n",
      "[1,   150] loss: 1.882\n",
      "[1,   180] loss: 1.896\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[2,    30] loss: 1.895\n",
      "[2,    60] loss: 1.889\n",
      "[2,    90] loss: 1.895\n",
      "[2,   120] loss: 1.871\n",
      "[2,   150] loss: 1.875\n",
      "[2,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[3,    30] loss: 1.886\n",
      "[3,    60] loss: 1.883\n",
      "[3,    90] loss: 1.893\n",
      "[3,   120] loss: 1.875\n",
      "[3,   150] loss: 1.883\n",
      "[3,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[4,    30] loss: 1.884\n",
      "[4,    60] loss: 1.893\n",
      "[4,    90] loss: 1.874\n",
      "[4,   120] loss: 1.883\n",
      "[4,   150] loss: 1.876\n",
      "[4,   180] loss: 1.896\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[5,    30] loss: 1.886\n",
      "[5,    60] loss: 1.875\n",
      "[5,    90] loss: 1.875\n",
      "[5,   120] loss: 1.899\n",
      "[5,   150] loss: 1.885\n",
      "[5,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[6,    30] loss: 1.886\n",
      "[6,    60] loss: 1.877\n",
      "[6,    90] loss: 1.893\n",
      "[6,   120] loss: 1.890\n",
      "[6,   150] loss: 1.884\n",
      "[6,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[7,    30] loss: 1.883\n",
      "[7,    60] loss: 1.865\n",
      "[7,    90] loss: 1.893\n",
      "[7,   120] loss: 1.894\n",
      "[7,   150] loss: 1.886\n",
      "[7,   180] loss: 1.888\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[8,    30] loss: 1.890\n",
      "[8,    60] loss: 1.880\n",
      "[8,    90] loss: 1.889\n",
      "[8,   120] loss: 1.884\n",
      "[8,   150] loss: 1.877\n",
      "[8,   180] loss: 1.878\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[9,    30] loss: 1.881\n",
      "[9,    60] loss: 1.877\n",
      "[9,    90] loss: 1.879\n",
      "[9,   120] loss: 1.884\n",
      "[9,   150] loss: 1.883\n",
      "[9,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[10,    30] loss: 1.884\n",
      "[10,    60] loss: 1.882\n",
      "[10,    90] loss: 1.877\n",
      "[10,   120] loss: 1.887\n",
      "[10,   150] loss: 1.897\n",
      "[10,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[11,    30] loss: 1.886\n",
      "[11,    60] loss: 1.891\n",
      "[11,    90] loss: 1.880\n",
      "[11,   120] loss: 1.883\n",
      "[11,   150] loss: 1.873\n",
      "[11,   180] loss: 1.884\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[12,    30] loss: 1.877\n",
      "[12,    60] loss: 1.902\n",
      "[12,    90] loss: 1.887\n",
      "[12,   120] loss: 1.882\n",
      "[12,   150] loss: 1.885\n",
      "[12,   180] loss: 1.875\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[13,    30] loss: 1.879\n",
      "[13,    60] loss: 1.880\n",
      "[13,    90] loss: 1.880\n",
      "[13,   120] loss: 1.880\n",
      "[13,   150] loss: 1.887\n",
      "[13,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[14,    30] loss: 1.875\n",
      "[14,    60] loss: 1.882\n",
      "[14,    90] loss: 1.899\n",
      "[14,   120] loss: 1.878\n",
      "[14,   150] loss: 1.876\n",
      "[14,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[15,    30] loss: 1.882\n",
      "[15,    60] loss: 1.879\n",
      "[15,    90] loss: 1.881\n",
      "[15,   120] loss: 1.893\n",
      "[15,   150] loss: 1.889\n",
      "[15,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[16,    30] loss: 1.887\n",
      "[16,    60] loss: 1.893\n",
      "[16,    90] loss: 1.881\n",
      "[16,   120] loss: 1.890\n",
      "[16,   150] loss: 1.875\n",
      "[16,   180] loss: 1.873\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[17,    30] loss: 1.879\n",
      "[17,    60] loss: 1.893\n",
      "[17,    90] loss: 1.893\n",
      "[17,   120] loss: 1.877\n",
      "[17,   150] loss: 1.882\n",
      "[17,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[18,    30] loss: 1.882\n",
      "[18,    60] loss: 1.878\n",
      "[18,    90] loss: 1.896\n",
      "[18,   120] loss: 1.883\n",
      "[18,   150] loss: 1.883\n",
      "[18,   180] loss: 1.884\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[19,    30] loss: 1.883\n",
      "[19,    60] loss: 1.873\n",
      "[19,    90] loss: 1.880\n",
      "[19,   120] loss: 1.893\n",
      "[19,   150] loss: 1.899\n",
      "[19,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[20,    30] loss: 1.884\n",
      "[20,    60] loss: 1.900\n",
      "[20,    90] loss: 1.879\n",
      "[20,   120] loss: 1.887\n",
      "[20,   150] loss: 1.886\n",
      "[20,   180] loss: 1.869\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[21,    30] loss: 1.878\n",
      "[21,    60] loss: 1.894\n",
      "[21,    90] loss: 1.891\n",
      "[21,   120] loss: 1.882\n",
      "[21,   150] loss: 1.888\n",
      "[21,   180] loss: 1.886\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[22,    30] loss: 1.891\n",
      "[22,    60] loss: 1.897\n",
      "[22,    90] loss: 1.885\n",
      "[22,   120] loss: 1.881\n",
      "[22,   150] loss: 1.874\n",
      "[22,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[23,    30] loss: 1.888\n",
      "[23,    60] loss: 1.892\n",
      "[23,    90] loss: 1.874\n",
      "[23,   120] loss: 1.887\n",
      "[23,   150] loss: 1.888\n",
      "[23,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[24,    30] loss: 1.884\n",
      "[24,    60] loss: 1.884\n",
      "[24,    90] loss: 1.881\n",
      "[24,   120] loss: 1.878\n",
      "[24,   150] loss: 1.882\n",
      "[24,   180] loss: 1.878\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[25,    30] loss: 1.887\n",
      "[25,    60] loss: 1.871\n",
      "[25,    90] loss: 1.893\n",
      "[25,   120] loss: 1.879\n",
      "[25,   150] loss: 1.887\n",
      "[25,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[26,    30] loss: 1.875\n",
      "[26,    60] loss: 1.893\n",
      "[26,    90] loss: 1.884\n",
      "[26,   120] loss: 1.881\n",
      "[26,   150] loss: 1.878\n",
      "[26,   180] loss: 1.889\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[27,    30] loss: 1.886\n",
      "[27,    60] loss: 1.899\n",
      "[27,    90] loss: 1.882\n",
      "[27,   120] loss: 1.881\n",
      "[27,   150] loss: 1.884\n",
      "[27,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[28,    30] loss: 1.884\n",
      "[28,    60] loss: 1.892\n",
      "[28,    90] loss: 1.873\n",
      "[28,   120] loss: 1.880\n",
      "[28,   150] loss: 1.890\n",
      "[28,   180] loss: 1.863\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[29,    30] loss: 1.896\n",
      "[29,    60] loss: 1.890\n",
      "[29,    90] loss: 1.880\n",
      "[29,   120] loss: 1.888\n",
      "[29,   150] loss: 1.870\n",
      "[29,   180] loss: 1.874\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[30,    30] loss: 1.884\n",
      "[30,    60] loss: 1.878\n",
      "[30,    90] loss: 1.874\n",
      "[30,   120] loss: 1.888\n",
      "[30,   150] loss: 1.887\n",
      "[30,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[31,    30] loss: 1.890\n",
      "[31,    60] loss: 1.884\n",
      "[31,    90] loss: 1.886\n",
      "[31,   120] loss: 1.881\n",
      "[31,   150] loss: 1.873\n",
      "[31,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[32,    30] loss: 1.891\n",
      "[32,    60] loss: 1.888\n",
      "[32,    90] loss: 1.868\n",
      "[32,   120] loss: 1.881\n",
      "[32,   150] loss: 1.895\n",
      "[32,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[33,    30] loss: 1.889\n",
      "[33,    60] loss: 1.884\n",
      "[33,    90] loss: 1.884\n",
      "[33,   120] loss: 1.885\n",
      "[33,   150] loss: 1.884\n",
      "[33,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[34,    30] loss: 1.889\n",
      "[34,    60] loss: 1.887\n",
      "[34,    90] loss: 1.887\n",
      "[34,   120] loss: 1.882\n",
      "[34,   150] loss: 1.876\n",
      "[34,   180] loss: 1.873\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[35,    30] loss: 1.885\n",
      "[35,    60] loss: 1.887\n",
      "[35,    90] loss: 1.882\n",
      "[35,   120] loss: 1.882\n",
      "[35,   150] loss: 1.881\n",
      "[35,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[36,    30] loss: 1.886\n",
      "[36,    60] loss: 1.878\n",
      "[36,    90] loss: 1.882\n",
      "[36,   120] loss: 1.896\n",
      "[36,   150] loss: 1.873\n",
      "[36,   180] loss: 1.889\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[37,    30] loss: 1.880\n",
      "[37,    60] loss: 1.884\n",
      "[37,    90] loss: 1.884\n",
      "[37,   120] loss: 1.871\n",
      "[37,   150] loss: 1.890\n",
      "[37,   180] loss: 1.893\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[38,    30] loss: 1.866\n",
      "[38,    60] loss: 1.889\n",
      "[38,    90] loss: 1.888\n",
      "[38,   120] loss: 1.877\n",
      "[38,   150] loss: 1.875\n",
      "[38,   180] loss: 1.907\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[39,    30] loss: 1.884\n",
      "[39,    60] loss: 1.873\n",
      "[39,    90] loss: 1.885\n",
      "[39,   120] loss: 1.894\n",
      "[39,   150] loss: 1.886\n",
      "[39,   180] loss: 1.889\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[40,    30] loss: 1.889\n",
      "[40,    60] loss: 1.887\n",
      "[40,    90] loss: 1.885\n",
      "[40,   120] loss: 1.879\n",
      "[40,   150] loss: 1.887\n",
      "[40,   180] loss: 1.871\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[41,    30] loss: 1.874\n",
      "[41,    60] loss: 1.888\n",
      "[41,    90] loss: 1.873\n",
      "[41,   120] loss: 1.882\n",
      "[41,   150] loss: 1.885\n",
      "[41,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[42,    30] loss: 1.893\n",
      "[42,    60] loss: 1.884\n",
      "[42,    90] loss: 1.876\n",
      "[42,   120] loss: 1.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42,   150] loss: 1.877\n",
      "[42,   180] loss: 1.894\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[43,    30] loss: 1.883\n",
      "[43,    60] loss: 1.899\n",
      "[43,    90] loss: 1.895\n",
      "[43,   120] loss: 1.876\n",
      "[43,   150] loss: 1.875\n",
      "[43,   180] loss: 1.868\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[44,    30] loss: 1.884\n",
      "[44,    60] loss: 1.875\n",
      "[44,    90] loss: 1.872\n",
      "[44,   120] loss: 1.889\n",
      "[44,   150] loss: 1.891\n",
      "[44,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[45,    30] loss: 1.875\n",
      "[45,    60] loss: 1.883\n",
      "[45,    90] loss: 1.895\n",
      "[45,   120] loss: 1.891\n",
      "[45,   150] loss: 1.884\n",
      "[45,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[46,    30] loss: 1.879\n",
      "[46,    60] loss: 1.880\n",
      "[46,    90] loss: 1.883\n",
      "[46,   120] loss: 1.889\n",
      "[46,   150] loss: 1.885\n",
      "[46,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[47,    30] loss: 1.883\n",
      "[47,    60] loss: 1.890\n",
      "[47,    90] loss: 1.875\n",
      "[47,   120] loss: 1.884\n",
      "[47,   150] loss: 1.892\n",
      "[47,   180] loss: 1.876\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[48,    30] loss: 1.885\n",
      "[48,    60] loss: 1.884\n",
      "[48,    90] loss: 1.878\n",
      "[48,   120] loss: 1.887\n",
      "[48,   150] loss: 1.877\n",
      "[48,   180] loss: 1.893\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[49,    30] loss: 1.884\n",
      "[49,    60] loss: 1.882\n",
      "[49,    90] loss: 1.888\n",
      "[49,   120] loss: 1.882\n",
      "[49,   150] loss: 1.883\n",
      "[49,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[50,    30] loss: 1.882\n",
      "[50,    60] loss: 1.886\n",
      "[50,    90] loss: 1.880\n",
      "[50,   120] loss: 1.892\n",
      "[50,   150] loss: 1.871\n",
      "[50,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[51,    30] loss: 1.879\n",
      "[51,    60] loss: 1.881\n",
      "[51,    90] loss: 1.882\n",
      "[51,   120] loss: 1.882\n",
      "[51,   150] loss: 1.897\n",
      "[51,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[52,    30] loss: 1.880\n",
      "[52,    60] loss: 1.879\n",
      "[52,    90] loss: 1.891\n",
      "[52,   120] loss: 1.883\n",
      "[52,   150] loss: 1.871\n",
      "[52,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[53,    30] loss: 1.888\n",
      "[53,    60] loss: 1.887\n",
      "[53,    90] loss: 1.876\n",
      "[53,   120] loss: 1.889\n",
      "[53,   150] loss: 1.880\n",
      "[53,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[54,    30] loss: 1.877\n",
      "[54,    60] loss: 1.886\n",
      "[54,    90] loss: 1.890\n",
      "[54,   120] loss: 1.897\n",
      "[54,   150] loss: 1.876\n",
      "[54,   180] loss: 1.888\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[55,    30] loss: 1.889\n",
      "[55,    60] loss: 1.879\n",
      "[55,    90] loss: 1.888\n",
      "[55,   120] loss: 1.880\n",
      "[55,   150] loss: 1.888\n",
      "[55,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[56,    30] loss: 1.879\n",
      "[56,    60] loss: 1.881\n",
      "[56,    90] loss: 1.884\n",
      "[56,   120] loss: 1.886\n",
      "[56,   150] loss: 1.890\n",
      "[56,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[57,    30] loss: 1.879\n",
      "[57,    60] loss: 1.899\n",
      "[57,    90] loss: 1.875\n",
      "[57,   120] loss: 1.886\n",
      "[57,   150] loss: 1.886\n",
      "[57,   180] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[58,    30] loss: 1.877\n",
      "[58,    60] loss: 1.880\n",
      "[58,    90] loss: 1.899\n",
      "[58,   120] loss: 1.876\n",
      "[58,   150] loss: 1.891\n",
      "[58,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[59,    30] loss: 1.890\n",
      "[59,    60] loss: 1.894\n",
      "[59,    90] loss: 1.886\n",
      "[59,   120] loss: 1.892\n",
      "[59,   150] loss: 1.868\n",
      "[59,   180] loss: 1.880\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[60,    30] loss: 1.892\n",
      "[60,    60] loss: 1.879\n",
      "[60,    90] loss: 1.882\n",
      "[60,   120] loss: 1.873\n",
      "[60,   150] loss: 1.870\n",
      "[60,   180] loss: 1.894\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[61,    30] loss: 1.887\n",
      "[61,    60] loss: 1.870\n",
      "[61,    90] loss: 1.892\n",
      "[61,   120] loss: 1.889\n",
      "[61,   150] loss: 1.877\n",
      "[61,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[62,    30] loss: 1.879\n",
      "[62,    60] loss: 1.891\n",
      "[62,    90] loss: 1.879\n",
      "[62,   120] loss: 1.888\n",
      "[62,   150] loss: 1.882\n",
      "[62,   180] loss: 1.884\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[63,    30] loss: 1.892\n",
      "[63,    60] loss: 1.889\n",
      "[63,    90] loss: 1.874\n",
      "[63,   120] loss: 1.880\n",
      "[63,   150] loss: 1.875\n",
      "[63,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[64,    30] loss: 1.872\n",
      "[64,    60] loss: 1.887\n",
      "[64,    90] loss: 1.876\n",
      "[64,   120] loss: 1.898\n",
      "[64,   150] loss: 1.888\n",
      "[64,   180] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[65,    30] loss: 1.885\n",
      "[65,    60] loss: 1.874\n",
      "[65,    90] loss: 1.898\n",
      "[65,   120] loss: 1.886\n",
      "[65,   150] loss: 1.872\n",
      "[65,   180] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[66,    30] loss: 1.887\n",
      "[66,    60] loss: 1.887\n",
      "[66,    90] loss: 1.881\n",
      "[66,   120] loss: 1.886\n",
      "[66,   150] loss: 1.874\n",
      "[66,   180] loss: 1.888\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[67,    30] loss: 1.890\n",
      "[67,    60] loss: 1.878\n",
      "[67,    90] loss: 1.880\n",
      "[67,   120] loss: 1.888\n",
      "[67,   150] loss: 1.894\n",
      "[67,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[68,    30] loss: 1.878\n",
      "[68,    60] loss: 1.883\n",
      "[68,    90] loss: 1.883\n",
      "[68,   120] loss: 1.887\n",
      "[68,   150] loss: 1.868\n",
      "[68,   180] loss: 1.889\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[69,    30] loss: 1.896\n",
      "[69,    60] loss: 1.898\n",
      "[69,    90] loss: 1.890\n",
      "[69,   120] loss: 1.884\n",
      "[69,   150] loss: 1.882\n",
      "[69,   180] loss: 1.875\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[70,    30] loss: 1.881\n",
      "[70,    60] loss: 1.881\n",
      "[70,    90] loss: 1.900\n",
      "[70,   120] loss: 1.887\n",
      "[70,   150] loss: 1.878\n",
      "[70,   180] loss: 1.878\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[71,    30] loss: 1.880\n",
      "[71,    60] loss: 1.879\n",
      "[71,    90] loss: 1.895\n",
      "[71,   120] loss: 1.885\n",
      "[71,   150] loss: 1.880\n",
      "[71,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[72,    30] loss: 1.885\n",
      "[72,    60] loss: 1.878\n",
      "[72,    90] loss: 1.882\n",
      "[72,   120] loss: 1.894\n",
      "[72,   150] loss: 1.872\n",
      "[72,   180] loss: 1.894\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[73,    30] loss: 1.900\n",
      "[73,    60] loss: 1.887\n",
      "[73,    90] loss: 1.893\n",
      "[73,   120] loss: 1.876\n",
      "[73,   150] loss: 1.886\n",
      "[73,   180] loss: 1.867\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[74,    30] loss: 1.885\n",
      "[74,    60] loss: 1.883\n",
      "[74,    90] loss: 1.882\n",
      "[74,   120] loss: 1.884\n",
      "[74,   150] loss: 1.888\n",
      "[74,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[75,    30] loss: 1.876\n",
      "[75,    60] loss: 1.871\n",
      "[75,    90] loss: 1.883\n",
      "[75,   120] loss: 1.896\n",
      "[75,   150] loss: 1.892\n",
      "[75,   180] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[76,    30] loss: 1.895\n",
      "[76,    60] loss: 1.893\n",
      "[76,    90] loss: 1.877\n",
      "[76,   120] loss: 1.894\n",
      "[76,   150] loss: 1.872\n",
      "[76,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[77,    30] loss: 1.891\n",
      "[77,    60] loss: 1.877\n",
      "[77,    90] loss: 1.879\n",
      "[77,   120] loss: 1.883\n",
      "[77,   150] loss: 1.883\n",
      "[77,   180] loss: 1.890\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[78,    30] loss: 1.880\n",
      "[78,    60] loss: 1.894\n",
      "[78,    90] loss: 1.886\n",
      "[78,   120] loss: 1.879\n",
      "[78,   150] loss: 1.884\n",
      "[78,   180] loss: 1.888\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[79,    30] loss: 1.882\n",
      "[79,    60] loss: 1.874\n",
      "[79,    90] loss: 1.894\n",
      "[79,   120] loss: 1.889\n",
      "[79,   150] loss: 1.870\n",
      "[79,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[80,    30] loss: 1.873\n",
      "[80,    60] loss: 1.891\n",
      "[80,    90] loss: 1.890\n",
      "[80,   120] loss: 1.886\n",
      "[80,   150] loss: 1.877\n",
      "[80,   180] loss: 1.895\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[81,    30] loss: 1.885\n",
      "[81,    60] loss: 1.901\n",
      "[81,    90] loss: 1.878\n",
      "[81,   120] loss: 1.880\n",
      "[81,   150] loss: 1.895\n",
      "[81,   180] loss: 1.867\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[82,    30] loss: 1.872\n",
      "[82,    60] loss: 1.879\n",
      "[82,    90] loss: 1.894\n",
      "[82,   120] loss: 1.880\n",
      "[82,   150] loss: 1.888\n",
      "[82,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[83,    30] loss: 1.883\n",
      "[83,    60] loss: 1.871\n",
      "[83,    90] loss: 1.878\n",
      "[83,   120] loss: 1.890\n",
      "[83,   150] loss: 1.884\n",
      "[83,   180] loss: 1.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[84,    30] loss: 1.884\n",
      "[84,    60] loss: 1.882\n",
      "[84,    90] loss: 1.893\n",
      "[84,   120] loss: 1.882\n",
      "[84,   150] loss: 1.891\n",
      "[84,   180] loss: 1.880\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[85,    30] loss: 1.904\n",
      "[85,    60] loss: 1.878\n",
      "[85,    90] loss: 1.877\n",
      "[85,   120] loss: 1.877\n",
      "[85,   150] loss: 1.877\n",
      "[85,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[86,    30] loss: 1.885\n",
      "[86,    60] loss: 1.889\n",
      "[86,    90] loss: 1.893\n",
      "[86,   120] loss: 1.881\n",
      "[86,   150] loss: 1.892\n",
      "[86,   180] loss: 1.868\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[87,    30] loss: 1.880\n",
      "[87,    60] loss: 1.892\n",
      "[87,    90] loss: 1.892\n",
      "[87,   120] loss: 1.874\n",
      "[87,   150] loss: 1.882\n",
      "[87,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[88,    30] loss: 1.879\n",
      "[88,    60] loss: 1.878\n",
      "[88,    90] loss: 1.889\n",
      "[88,   120] loss: 1.896\n",
      "[88,   150] loss: 1.886\n",
      "[88,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[89,    30] loss: 1.884\n",
      "[89,    60] loss: 1.887\n",
      "[89,    90] loss: 1.875\n",
      "[89,   120] loss: 1.886\n",
      "[89,   150] loss: 1.877\n",
      "[89,   180] loss: 1.896\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[90,    30] loss: 1.879\n",
      "[90,    60] loss: 1.888\n",
      "[90,    90] loss: 1.872\n",
      "[90,   120] loss: 1.882\n",
      "[90,   150] loss: 1.883\n",
      "[90,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[91,    30] loss: 1.886\n",
      "[91,    60] loss: 1.886\n",
      "[91,    90] loss: 1.885\n",
      "[91,   120] loss: 1.894\n",
      "[91,   150] loss: 1.875\n",
      "[91,   180] loss: 1.876\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[92,    30] loss: 1.888\n",
      "[92,    60] loss: 1.886\n",
      "[92,    90] loss: 1.872\n",
      "[92,   120] loss: 1.888\n",
      "[92,   150] loss: 1.885\n",
      "[92,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[93,    30] loss: 1.899\n",
      "[93,    60] loss: 1.879\n",
      "[93,    90] loss: 1.875\n",
      "[93,   120] loss: 1.884\n",
      "[93,   150] loss: 1.878\n",
      "[93,   180] loss: 1.876\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[94,    30] loss: 1.879\n",
      "[94,    60] loss: 1.888\n",
      "[94,    90] loss: 1.880\n",
      "[94,   120] loss: 1.880\n",
      "[94,   150] loss: 1.888\n",
      "[94,   180] loss: 1.889\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[95,    30] loss: 1.887\n",
      "[95,    60] loss: 1.873\n",
      "[95,    90] loss: 1.909\n",
      "[95,   120] loss: 1.890\n",
      "[95,   150] loss: 1.876\n",
      "[95,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[96,    30] loss: 1.875\n",
      "[96,    60] loss: 1.884\n",
      "[96,    90] loss: 1.891\n",
      "[96,   120] loss: 1.888\n",
      "[96,   150] loss: 1.882\n",
      "[96,   180] loss: 1.880\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[97,    30] loss: 1.877\n",
      "[97,    60] loss: 1.891\n",
      "[97,    90] loss: 1.876\n",
      "[97,   120] loss: 1.895\n",
      "[97,   150] loss: 1.890\n",
      "[97,   180] loss: 1.874\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[98,    30] loss: 1.891\n",
      "[98,    60] loss: 1.882\n",
      "[98,    90] loss: 1.886\n",
      "[98,   120] loss: 1.878\n",
      "[98,   150] loss: 1.881\n",
      "[98,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[99,    30] loss: 1.891\n",
      "[99,    60] loss: 1.876\n",
      "[99,    90] loss: 1.883\n",
      "[99,   120] loss: 1.881\n",
      "[99,   150] loss: 1.863\n",
      "[99,   180] loss: 1.893\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[100,    30] loss: 1.890\n",
      "[100,    60] loss: 1.877\n",
      "[100,    90] loss: 1.882\n",
      "[100,   120] loss: 1.874\n",
      "[100,   150] loss: 1.883\n",
      "[100,   180] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[101,    30] loss: 1.888\n",
      "[101,    60] loss: 1.889\n",
      "[101,    90] loss: 1.888\n",
      "[101,   120] loss: 1.876\n",
      "[101,   150] loss: 1.899\n",
      "[101,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[102,    30] loss: 1.880\n",
      "[102,    60] loss: 1.874\n",
      "[102,    90] loss: 1.881\n",
      "[102,   120] loss: 1.904\n",
      "[102,   150] loss: 1.877\n",
      "[102,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[103,    30] loss: 1.897\n",
      "[103,    60] loss: 1.873\n",
      "[103,    90] loss: 1.880\n",
      "[103,   120] loss: 1.883\n",
      "[103,   150] loss: 1.896\n",
      "[103,   180] loss: 1.871\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[104,    30] loss: 1.890\n",
      "[104,    60] loss: 1.887\n",
      "[104,    90] loss: 1.878\n",
      "[104,   120] loss: 1.878\n",
      "[104,   150] loss: 1.896\n",
      "[104,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[105,    30] loss: 1.880\n",
      "[105,    60] loss: 1.888\n",
      "[105,    90] loss: 1.882\n",
      "[105,   120] loss: 1.874\n",
      "[105,   150] loss: 1.876\n",
      "[105,   180] loss: 1.888\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[106,    30] loss: 1.874\n",
      "[106,    60] loss: 1.889\n",
      "[106,    90] loss: 1.881\n",
      "[106,   120] loss: 1.873\n",
      "[106,   150] loss: 1.884\n",
      "[106,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[107,    30] loss: 1.889\n",
      "[107,    60] loss: 1.882\n",
      "[107,    90] loss: 1.888\n",
      "[107,   120] loss: 1.878\n",
      "[107,   150] loss: 1.874\n",
      "[107,   180] loss: 1.890\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[108,    30] loss: 1.882\n",
      "[108,    60] loss: 1.885\n",
      "[108,    90] loss: 1.879\n",
      "[108,   120] loss: 1.887\n",
      "[108,   150] loss: 1.888\n",
      "[108,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[109,    30] loss: 1.884\n",
      "[109,    60] loss: 1.891\n",
      "[109,    90] loss: 1.879\n",
      "[109,   120] loss: 1.885\n",
      "[109,   150] loss: 1.875\n",
      "[109,   180] loss: 1.886\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[110,    30] loss: 1.879\n",
      "[110,    60] loss: 1.881\n",
      "[110,    90] loss: 1.882\n",
      "[110,   120] loss: 1.885\n",
      "[110,   150] loss: 1.884\n",
      "[110,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[111,    30] loss: 1.885\n",
      "[111,    60] loss: 1.868\n",
      "[111,    90] loss: 1.875\n",
      "[111,   120] loss: 1.890\n",
      "[111,   150] loss: 1.869\n",
      "[111,   180] loss: 1.893\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[112,    30] loss: 1.890\n",
      "[112,    60] loss: 1.879\n",
      "[112,    90] loss: 1.887\n",
      "[112,   120] loss: 1.879\n",
      "[112,   150] loss: 1.892\n",
      "[112,   180] loss: 1.875\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[113,    30] loss: 1.889\n",
      "[113,    60] loss: 1.881\n",
      "[113,    90] loss: 1.870\n",
      "[113,   120] loss: 1.882\n",
      "[113,   150] loss: 1.888\n",
      "[113,   180] loss: 1.886\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[114,    30] loss: 1.900\n",
      "[114,    60] loss: 1.874\n",
      "[114,    90] loss: 1.885\n",
      "[114,   120] loss: 1.880\n",
      "[114,   150] loss: 1.881\n",
      "[114,   180] loss: 1.884\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[115,    30] loss: 1.875\n",
      "[115,    60] loss: 1.879\n",
      "[115,    90] loss: 1.889\n",
      "[115,   120] loss: 1.887\n",
      "[115,   150] loss: 1.881\n",
      "[115,   180] loss: 1.876\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[116,    30] loss: 1.893\n",
      "[116,    60] loss: 1.885\n",
      "[116,    90] loss: 1.872\n",
      "[116,   120] loss: 1.873\n",
      "[116,   150] loss: 1.899\n",
      "[116,   180] loss: 1.880\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[117,    30] loss: 1.886\n",
      "[117,    60] loss: 1.875\n",
      "[117,    90] loss: 1.876\n",
      "[117,   120] loss: 1.882\n",
      "[117,   150] loss: 1.875\n",
      "[117,   180] loss: 1.898\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[118,    30] loss: 1.888\n",
      "[118,    60] loss: 1.891\n",
      "[118,    90] loss: 1.891\n",
      "[118,   120] loss: 1.882\n",
      "[118,   150] loss: 1.882\n",
      "[118,   180] loss: 1.890\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[119,    30] loss: 1.876\n",
      "[119,    60] loss: 1.877\n",
      "[119,    90] loss: 1.879\n",
      "[119,   120] loss: 1.892\n",
      "[119,   150] loss: 1.887\n",
      "[119,   180] loss: 1.873\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[120,    30] loss: 1.880\n",
      "[120,    60] loss: 1.889\n",
      "[120,    90] loss: 1.880\n",
      "[120,   120] loss: 1.866\n",
      "[120,   150] loss: 1.892\n",
      "[120,   180] loss: 1.895\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[121,    30] loss: 1.885\n",
      "[121,    60] loss: 1.873\n",
      "[121,    90] loss: 1.879\n",
      "[121,   120] loss: 1.873\n",
      "[121,   150] loss: 1.903\n",
      "[121,   180] loss: 1.892\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[122,    30] loss: 1.883\n",
      "[122,    60] loss: 1.886\n",
      "[122,    90] loss: 1.894\n",
      "[122,   120] loss: 1.888\n",
      "[122,   150] loss: 1.869\n",
      "[122,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[123,    30] loss: 1.890\n",
      "[123,    60] loss: 1.881\n",
      "[123,    90] loss: 1.890\n",
      "[123,   120] loss: 1.880\n",
      "[123,   150] loss: 1.874\n",
      "[123,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[124,    30] loss: 1.883\n",
      "[124,    60] loss: 1.879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124,    90] loss: 1.891\n",
      "[124,   120] loss: 1.901\n",
      "[124,   150] loss: 1.884\n",
      "[124,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[125,    30] loss: 1.887\n",
      "[125,    60] loss: 1.885\n",
      "[125,    90] loss: 1.900\n",
      "[125,   120] loss: 1.872\n",
      "[125,   150] loss: 1.883\n",
      "[125,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[126,    30] loss: 1.891\n",
      "[126,    60] loss: 1.885\n",
      "[126,    90] loss: 1.886\n",
      "[126,   120] loss: 1.880\n",
      "[126,   150] loss: 1.875\n",
      "[126,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[127,    30] loss: 1.896\n",
      "[127,    60] loss: 1.877\n",
      "[127,    90] loss: 1.885\n",
      "[127,   120] loss: 1.873\n",
      "[127,   150] loss: 1.885\n",
      "[127,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[128,    30] loss: 1.893\n",
      "[128,    60] loss: 1.875\n",
      "[128,    90] loss: 1.884\n",
      "[128,   120] loss: 1.888\n",
      "[128,   150] loss: 1.890\n",
      "[128,   180] loss: 1.879\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[129,    30] loss: 1.877\n",
      "[129,    60] loss: 1.883\n",
      "[129,    90] loss: 1.883\n",
      "[129,   120] loss: 1.891\n",
      "[129,   150] loss: 1.881\n",
      "[129,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[130,    30] loss: 1.888\n",
      "[130,    60] loss: 1.893\n",
      "[130,    90] loss: 1.872\n",
      "[130,   120] loss: 1.883\n",
      "[130,   150] loss: 1.882\n",
      "[130,   180] loss: 1.885\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[131,    30] loss: 1.894\n",
      "[131,    60] loss: 1.881\n",
      "[131,    90] loss: 1.890\n",
      "[131,   120] loss: 1.888\n",
      "[131,   150] loss: 1.872\n",
      "[131,   180] loss: 1.873\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[132,    30] loss: 1.892\n",
      "[132,    60] loss: 1.887\n",
      "[132,    90] loss: 1.887\n",
      "[132,   120] loss: 1.876\n",
      "[132,   150] loss: 1.905\n",
      "[132,   180] loss: 1.872\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[133,    30] loss: 1.867\n",
      "[133,    60] loss: 1.897\n",
      "[133,    90] loss: 1.898\n",
      "[133,   120] loss: 1.878\n",
      "[133,   150] loss: 1.885\n",
      "[133,   180] loss: 1.882\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[134,    30] loss: 1.872\n",
      "[134,    60] loss: 1.894\n",
      "[134,    90] loss: 1.876\n",
      "[134,   120] loss: 1.892\n",
      "[134,   150] loss: 1.885\n",
      "[134,   180] loss: 1.878\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[135,    30] loss: 1.884\n",
      "[135,    60] loss: 1.891\n",
      "[135,    90] loss: 1.864\n",
      "[135,   120] loss: 1.875\n",
      "[135,   150] loss: 1.898\n",
      "[135,   180] loss: 1.891\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[136,    30] loss: 1.882\n",
      "[136,    60] loss: 1.885\n",
      "[136,    90] loss: 1.882\n",
      "[136,   120] loss: 1.882\n",
      "[136,   150] loss: 1.877\n",
      "[136,   180] loss: 1.889\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[137,    30] loss: 1.883\n",
      "[137,    60] loss: 1.883\n",
      "[137,    90] loss: 1.879\n",
      "[137,   120] loss: 1.889\n",
      "[137,   150] loss: 1.880\n",
      "[137,   180] loss: 1.887\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[138,    30] loss: 1.895\n",
      "[138,    60] loss: 1.892\n",
      "[138,    90] loss: 1.882\n",
      "[138,   120] loss: 1.868\n",
      "[138,   150] loss: 1.877\n",
      "[138,   180] loss: 1.884\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[139,    30] loss: 1.876\n",
      "[139,    60] loss: 1.893\n",
      "[139,    90] loss: 1.876\n",
      "[139,   120] loss: 1.889\n",
      "[139,   150] loss: 1.892\n",
      "[139,   180] loss: 1.880\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[140,    30] loss: 1.884\n",
      "[140,    60] loss: 1.900\n",
      "[140,    90] loss: 1.883\n",
      "[140,   120] loss: 1.896\n",
      "[140,   150] loss: 1.865\n",
      "[140,   180] loss: 1.888\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[141,    30] loss: 1.890\n",
      "[141,    60] loss: 1.890\n",
      "[141,    90] loss: 1.880\n",
      "[141,   120] loss: 1.880\n",
      "[141,   150] loss: 1.890\n",
      "[141,   180] loss: 1.880\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[142,    30] loss: 1.891\n",
      "[142,    60] loss: 1.885\n",
      "[142,    90] loss: 1.888\n",
      "[142,   120] loss: 1.872\n",
      "[142,   150] loss: 1.885\n",
      "[142,   180] loss: 1.877\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[143,    30] loss: 1.887\n",
      "[143,    60] loss: 1.874\n",
      "[143,    90] loss: 1.885\n",
      "[143,   120] loss: 1.882\n",
      "[143,   150] loss: 1.881\n",
      "[143,   180] loss: 1.890\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[144,    30] loss: 1.905\n",
      "[144,    60] loss: 1.881\n",
      "[144,    90] loss: 1.864\n",
      "[144,   120] loss: 1.884\n",
      "[144,   150] loss: 1.878\n",
      "[144,   180] loss: 1.896\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[145,    30] loss: 1.885\n",
      "[145,    60] loss: 1.894\n",
      "[145,    90] loss: 1.873\n",
      "[145,   120] loss: 1.881\n",
      "[145,   150] loss: 1.884\n",
      "[145,   180] loss: 1.890\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[146,    30] loss: 1.899\n",
      "[146,    60] loss: 1.879\n",
      "[146,    90] loss: 1.884\n",
      "[146,   120] loss: 1.887\n",
      "[146,   150] loss: 1.884\n",
      "[146,   180] loss: 1.874\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[147,    30] loss: 1.892\n",
      "[147,    60] loss: 1.889\n",
      "[147,    90] loss: 1.886\n",
      "[147,   120] loss: 1.888\n",
      "[147,   150] loss: 1.879\n",
      "[147,   180] loss: 1.881\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[148,    30] loss: 1.879\n",
      "[148,    60] loss: 1.890\n",
      "[148,    90] loss: 1.875\n",
      "[148,   120] loss: 1.882\n",
      "[148,   150] loss: 1.878\n",
      "[148,   180] loss: 1.897\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[149,    30] loss: 1.878\n",
      "[149,    60] loss: 1.883\n",
      "[149,    90] loss: 1.883\n",
      "[149,   120] loss: 1.897\n",
      "[149,   150] loss: 1.884\n",
      "[149,   180] loss: 1.886\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "[150,    30] loss: 1.889\n",
      "[150,    60] loss: 1.884\n",
      "[150,    90] loss: 1.886\n",
      "[150,   120] loss: 1.882\n",
      "[150,   150] loss: 1.871\n",
      "[150,   180] loss: 1.883\n",
      "Accuracy of the network on the 10000 test images: 31 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 12. ResNet으로 학습 시작!\n",
    "print(len(trainloader))\n",
    "epochs = 150\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_sche.step()       # optimizer.step() 보다 뒤에서 실행\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:\n",
    "            value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch * len(trainloader)])) # value tracker\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "      \n",
    "    # epoch이 한 번 돌면, 정확도를 체크하고 정확도를 value_tracker에 저장\n",
    "    acc = acc_check(resnet50, testloader, epoch, save=1)\n",
    "    value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 31 %\n"
     ]
    }
   ],
   "source": [
    "# 13. 모델 평가\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = resnet50(images)\n",
    "    \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "        total += labels.size(0)\n",
    "    \n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' %(100 * correct / total))\n",
    "# Accuracy : 87%     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
